{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook starts from Preprocessed Dataframework. \"df_spark.csv\" is the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = pd.read_csv('df_spark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the following code X contains features and y contains label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_spark.iloc[:,0].values\n",
    "X = df_spark.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The whole dataset is split into 80:20 ratio. X_train contains 80% of the features, X_test contains 20% of the features and y_train contains 80% corresponding label of X_train and y_test contains 20% corresponding label of X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Fold Cross validation Estimation for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([('scl', StandardScaler()),('clf', LogisticRegression(penalty='l2', random_state=0))])\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr,X=X, y=y, train_sizes=np.linspace(0.2,1.0,5), cv=5, n_jobs=-1)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57270\n",
      "114540\n",
      "171811\n",
      "229081\n",
      "286352\n"
     ]
    }
   ],
   "source": [
    "for i in train_sizes:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9864361795006111\n",
      "0.986911122751877\n",
      "0.9868308781160694\n",
      "0.9865846578284538\n",
      "0.9883150807397888\n"
     ]
    }
   ],
   "source": [
    "for i in train_mean:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_mean:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Fold Cross validation Estimation for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tree = Pipeline([('scl', StandardScaler()),('clf', tree.DecisionTreeClassifier())])\n",
    "train_sizes_tree, train_scores_tree, test_scores_tree = learning_curve(estimator=pipe_tree,X=X, y=y, train_sizes=np.linspace(0.2,1.0,5), cv=5, n_jobs=-1)\n",
    "train_mean_tree = np.mean(train_scores_tree, axis=1)\n",
    "train_std_tree = np.std(train_scores_tree, axis=1)\n",
    "test_mean_tree = np.mean(test_scores_tree, axis=1)\n",
    "test_std_tree = np.std(test_scores_tree, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_mean_tree:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_mean_tree:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Fold Cross validation Estimation for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rnd = Pipeline([('scl', StandardScaler()),('clf', RandomForestClassifier(n_estimators=10))])\n",
    "train_sizes_rnd, train_scores_rnd, test_scores_rnd = learning_curve(estimator=pipe_rnd,X=X, y=y, train_sizes=np.linspace(0.2,1.0,5), cv=5, n_jobs=-1)\n",
    "train_mean_rnd = np.mean(train_scores_rnd, axis=1)\n",
    "train_std_rnd = np.std(train_scores_rnd, axis=1)\n",
    "test_mean_rnd = np.mean(test_scores_rnd, axis=1)\n",
    "test_std_rnd = np.std(test_scores_rnd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_mean_rnd:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_mean_rnd:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean values of Training and Testing accuracies and Standard Deviation of Training and Testing accuracies are given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_mean) , np.mean(train_mean_tree), np.mean(train_mean_rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_std) , np.mean(train_std_tree), np.mean(train_std_rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(test_mean) , np.mean(test_mean_tree), np.mean(test_mean_rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(test_std) ,np.mean(test_std_tree), np.mean(test_std_rnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics Calculations for Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = pipe_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = pipe_lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pipe_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Normal', 'DoSattack', 'scan', 'malitiousControl', 'malitiousOperation', 'spying', 'dataProbing', 'wrongSetUp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred_train, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cnf_matrix:\n",
    "    for j in i:\n",
    "        print(j, end='&')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb_model = nb.fit(X_train, y_train)\n",
    "nb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018117308525052733"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018117314996635124"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(nb_model, X_test, y_test, cv = 10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.02      1.00      0.03      1178\n",
      "         1.0       0.00      0.00      0.00        63\n",
      "         2.0       0.00      0.00      0.00       169\n",
      "         3.0       0.00      0.00      0.00       155\n",
      "         4.0       0.00      0.00      0.00       305\n",
      "         5.0       0.00      0.00      0.00       120\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "         7.0       1.00      0.00      0.00     69571\n",
      "\n",
      "    accuracy                           0.02     71589\n",
      "   macro avg       0.13      0.13      0.00     71589\n",
      "weighted avg       0.97      0.02      0.00     71589\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\metec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\metec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\metec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, nb_model.predict(X_test))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn_model = knn.fit(X_train, y_train)\n",
    "knn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9937001494643032"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      1.00      0.84      1178\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "         2.0       1.00      1.00      1.00       169\n",
      "         3.0       1.00      1.00      1.00       155\n",
      "         4.0       0.98      1.00      0.99       305\n",
      "         5.0       1.00      1.00      1.00       120\n",
      "         6.0       1.00      1.00      1.00        28\n",
      "         7.0       1.00      0.99      1.00     69571\n",
      "\n",
      "    accuracy                           0.99     71589\n",
      "   macro avg       0.96      1.00      0.98     71589\n",
      "weighted avg       1.00      0.99      0.99     71589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\metec\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9943706435346212"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.66      0.79      1178\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "         2.0       1.00      1.00      1.00       169\n",
      "         3.0       1.00      1.00      1.00       155\n",
      "         4.0       1.00      1.00      1.00       305\n",
      "         5.0       1.00      1.00      1.00       120\n",
      "         6.0       1.00      1.00      1.00        28\n",
      "         7.0       0.99      1.00      1.00     69571\n",
      "\n",
      "    accuracy                           0.99     71589\n",
      "   macro avg       1.00      0.96      0.97     71589\n",
      "weighted avg       0.99      0.99      0.99     71589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, xgb_model.predict(X_test))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-0.25.1-cp38-none-win_amd64.whl (66.9 MB)\n",
      "Requirement already satisfied: plotly in c:\\users\\metec\\anaconda3\\lib\\site-packages (from catboost) (4.14.1)\n",
      "Requirement already satisfied: graphviz in c:\\users\\metec\\anaconda3\\lib\\site-packages (from catboost) (0.16)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\metec\\anaconda3\\lib\\site-packages (from catboost) (1.18.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\metec\\anaconda3\\lib\\site-packages (from catboost) (3.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\metec\\anaconda3\\lib\\site-packages (from catboost) (1.5.0)\n",
      "Requirement already satisfied: six in c:\\users\\metec\\anaconda3\\lib\\site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\metec\\anaconda3\\lib\\site-packages (from catboost) (1.0.5)\n",
      "Requirement already satisfied: retrying>=1.3.3 in c:\\users\\metec\\anaconda3\\lib\\site-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\metec\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\metec\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\metec\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\metec\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\metec\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2020.1)\n",
      "Installing collected packages: catboost\n",
      "Successfully installed catboost-0.25.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.105591\n",
      "0:\tlearn: 1.4136248\ttotal: 421ms\tremaining: 7m\n",
      "1:\tlearn: 1.1192666\ttotal: 568ms\tremaining: 4m 43s\n",
      "2:\tlearn: 0.9256429\ttotal: 731ms\tremaining: 4m 2s\n",
      "3:\tlearn: 0.7824008\ttotal: 901ms\tremaining: 3m 44s\n",
      "4:\tlearn: 0.6726744\ttotal: 1.07s\tremaining: 3m 32s\n",
      "5:\tlearn: 0.5856969\ttotal: 1.22s\tremaining: 3m 21s\n",
      "6:\tlearn: 0.5141976\ttotal: 1.37s\tremaining: 3m 14s\n",
      "7:\tlearn: 0.4544402\ttotal: 1.53s\tremaining: 3m 9s\n",
      "8:\tlearn: 0.3992564\ttotal: 1.7s\tremaining: 3m 7s\n",
      "9:\tlearn: 0.3534927\ttotal: 1.87s\tremaining: 3m 4s\n",
      "10:\tlearn: 0.3161163\ttotal: 2.05s\tremaining: 3m 4s\n",
      "11:\tlearn: 0.2842506\ttotal: 2.21s\tremaining: 3m 1s\n",
      "12:\tlearn: 0.2546462\ttotal: 2.4s\tremaining: 3m 2s\n",
      "13:\tlearn: 0.2299275\ttotal: 2.58s\tremaining: 3m 1s\n",
      "14:\tlearn: 0.2062595\ttotal: 2.79s\tremaining: 3m 3s\n",
      "15:\tlearn: 0.1867672\ttotal: 2.98s\tremaining: 3m 3s\n",
      "16:\tlearn: 0.1705821\ttotal: 3.14s\tremaining: 3m 1s\n",
      "17:\tlearn: 0.1546674\ttotal: 3.34s\tremaining: 3m 2s\n",
      "18:\tlearn: 0.1410633\ttotal: 3.51s\tremaining: 3m 1s\n",
      "19:\tlearn: 0.1281810\ttotal: 3.7s\tremaining: 3m 1s\n",
      "20:\tlearn: 0.1172015\ttotal: 3.88s\tremaining: 3m\n",
      "21:\tlearn: 0.1082960\ttotal: 4.06s\tremaining: 3m\n",
      "22:\tlearn: 0.0990269\ttotal: 4.24s\tremaining: 3m\n",
      "23:\tlearn: 0.0911908\ttotal: 4.45s\tremaining: 3m\n",
      "24:\tlearn: 0.0838579\ttotal: 4.63s\tremaining: 3m\n",
      "25:\tlearn: 0.0772373\ttotal: 4.82s\tremaining: 3m\n",
      "26:\tlearn: 0.0718253\ttotal: 4.97s\tremaining: 2m 59s\n",
      "27:\tlearn: 0.0670150\ttotal: 5.14s\tremaining: 2m 58s\n",
      "28:\tlearn: 0.0621985\ttotal: 5.31s\tremaining: 2m 57s\n",
      "29:\tlearn: 0.0584094\ttotal: 5.49s\tremaining: 2m 57s\n",
      "30:\tlearn: 0.0552551\ttotal: 5.65s\tremaining: 2m 56s\n",
      "31:\tlearn: 0.0513061\ttotal: 5.82s\tremaining: 2m 56s\n",
      "32:\tlearn: 0.0486406\ttotal: 5.96s\tremaining: 2m 54s\n",
      "33:\tlearn: 0.0446727\ttotal: 6.13s\tremaining: 2m 54s\n",
      "34:\tlearn: 0.0414870\ttotal: 6.3s\tremaining: 2m 53s\n",
      "35:\tlearn: 0.0393024\ttotal: 6.49s\tremaining: 2m 53s\n",
      "36:\tlearn: 0.0376445\ttotal: 6.67s\tremaining: 2m 53s\n",
      "37:\tlearn: 0.0355828\ttotal: 6.85s\tremaining: 2m 53s\n",
      "38:\tlearn: 0.0341806\ttotal: 7.01s\tremaining: 2m 52s\n",
      "39:\tlearn: 0.0323529\ttotal: 7.23s\tremaining: 2m 53s\n",
      "40:\tlearn: 0.0310013\ttotal: 7.44s\tremaining: 2m 54s\n",
      "41:\tlearn: 0.0292601\ttotal: 7.62s\tremaining: 2m 53s\n",
      "42:\tlearn: 0.0277168\ttotal: 7.8s\tremaining: 2m 53s\n",
      "43:\tlearn: 0.0264841\ttotal: 7.98s\tremaining: 2m 53s\n",
      "44:\tlearn: 0.0255726\ttotal: 8.19s\tremaining: 2m 53s\n",
      "45:\tlearn: 0.0244042\ttotal: 8.46s\tremaining: 2m 55s\n",
      "46:\tlearn: 0.0232909\ttotal: 8.76s\tremaining: 2m 57s\n",
      "47:\tlearn: 0.0223708\ttotal: 9.06s\tremaining: 2m 59s\n",
      "48:\tlearn: 0.0216448\ttotal: 9.36s\tremaining: 3m 1s\n",
      "49:\tlearn: 0.0210527\ttotal: 9.8s\tremaining: 3m 6s\n",
      "50:\tlearn: 0.0204600\ttotal: 9.98s\tremaining: 3m 5s\n",
      "51:\tlearn: 0.0198866\ttotal: 10.2s\tremaining: 3m 6s\n",
      "52:\tlearn: 0.0193833\ttotal: 10.5s\tremaining: 3m 8s\n",
      "53:\tlearn: 0.0188888\ttotal: 10.8s\tremaining: 3m 9s\n",
      "54:\tlearn: 0.0184714\ttotal: 10.9s\tremaining: 3m 7s\n",
      "55:\tlearn: 0.0177786\ttotal: 11.1s\tremaining: 3m 7s\n",
      "56:\tlearn: 0.0171490\ttotal: 11.3s\tremaining: 3m 6s\n",
      "57:\tlearn: 0.0168666\ttotal: 11.5s\tremaining: 3m 6s\n",
      "58:\tlearn: 0.0163540\ttotal: 11.7s\tremaining: 3m 7s\n",
      "59:\tlearn: 0.0160095\ttotal: 11.9s\tremaining: 3m 6s\n",
      "60:\tlearn: 0.0154523\ttotal: 12.1s\tremaining: 3m 6s\n",
      "61:\tlearn: 0.0152476\ttotal: 12.2s\tremaining: 3m 5s\n",
      "62:\tlearn: 0.0149745\ttotal: 12.4s\tremaining: 3m 4s\n",
      "63:\tlearn: 0.0147188\ttotal: 12.6s\tremaining: 3m 4s\n",
      "64:\tlearn: 0.0145621\ttotal: 12.8s\tremaining: 3m 3s\n",
      "65:\tlearn: 0.0142535\ttotal: 13s\tremaining: 3m 4s\n",
      "66:\tlearn: 0.0140655\ttotal: 13.3s\tremaining: 3m 5s\n",
      "67:\tlearn: 0.0138643\ttotal: 13.6s\tremaining: 3m 6s\n",
      "68:\tlearn: 0.0136321\ttotal: 13.9s\tremaining: 3m 7s\n",
      "69:\tlearn: 0.0133960\ttotal: 14.2s\tremaining: 3m 8s\n",
      "70:\tlearn: 0.0131977\ttotal: 14.5s\tremaining: 3m 9s\n",
      "71:\tlearn: 0.0129555\ttotal: 14.7s\tremaining: 3m 8s\n",
      "72:\tlearn: 0.0128314\ttotal: 14.8s\tremaining: 3m 8s\n",
      "73:\tlearn: 0.0127165\ttotal: 15s\tremaining: 3m 7s\n",
      "74:\tlearn: 0.0124504\ttotal: 15.2s\tremaining: 3m 7s\n",
      "75:\tlearn: 0.0123609\ttotal: 15.4s\tremaining: 3m 6s\n",
      "76:\tlearn: 0.0122798\ttotal: 15.5s\tremaining: 3m 6s\n",
      "77:\tlearn: 0.0121730\ttotal: 15.7s\tremaining: 3m 5s\n",
      "78:\tlearn: 0.0119801\ttotal: 15.9s\tremaining: 3m 5s\n",
      "79:\tlearn: 0.0118726\ttotal: 16.2s\tremaining: 3m 6s\n",
      "80:\tlearn: 0.0117508\ttotal: 16.5s\tremaining: 3m 7s\n",
      "81:\tlearn: 0.0116494\ttotal: 16.8s\tremaining: 3m 8s\n",
      "82:\tlearn: 0.0115338\ttotal: 17.2s\tremaining: 3m 10s\n",
      "83:\tlearn: 0.0114629\ttotal: 17.5s\tremaining: 3m 10s\n",
      "84:\tlearn: 0.0113740\ttotal: 17.6s\tremaining: 3m 9s\n",
      "85:\tlearn: 0.0112672\ttotal: 17.8s\tremaining: 3m 9s\n",
      "86:\tlearn: 0.0111781\ttotal: 18s\tremaining: 3m 8s\n",
      "87:\tlearn: 0.0110793\ttotal: 18.2s\tremaining: 3m 8s\n",
      "88:\tlearn: 0.0109471\ttotal: 18.4s\tremaining: 3m 8s\n",
      "89:\tlearn: 0.0108964\ttotal: 18.6s\tremaining: 3m 7s\n",
      "90:\tlearn: 0.0107886\ttotal: 18.8s\tremaining: 3m 7s\n",
      "91:\tlearn: 0.0107223\ttotal: 19.1s\tremaining: 3m 8s\n",
      "92:\tlearn: 0.0106481\ttotal: 19.4s\tremaining: 3m 9s\n",
      "93:\tlearn: 0.0105698\ttotal: 19.7s\tremaining: 3m 10s\n",
      "94:\tlearn: 0.0105224\ttotal: 20s\tremaining: 3m 10s\n",
      "95:\tlearn: 0.0104537\ttotal: 20.3s\tremaining: 3m 11s\n",
      "96:\tlearn: 0.0104120\ttotal: 20.5s\tremaining: 3m 10s\n",
      "97:\tlearn: 0.0103629\ttotal: 20.7s\tremaining: 3m 10s\n",
      "98:\tlearn: 0.0103018\ttotal: 20.8s\tremaining: 3m 9s\n",
      "99:\tlearn: 0.0102624\ttotal: 21s\tremaining: 3m 8s\n",
      "100:\tlearn: 0.0102249\ttotal: 21.2s\tremaining: 3m 8s\n",
      "101:\tlearn: 0.0101760\ttotal: 21.4s\tremaining: 3m 7s\n",
      "102:\tlearn: 0.0101404\ttotal: 21.5s\tremaining: 3m 7s\n",
      "103:\tlearn: 0.0100791\ttotal: 21.7s\tremaining: 3m 7s\n",
      "104:\tlearn: 0.0100456\ttotal: 21.9s\tremaining: 3m 6s\n",
      "105:\tlearn: 0.0100043\ttotal: 22.2s\tremaining: 3m 6s\n",
      "106:\tlearn: 0.0099582\ttotal: 22.5s\tremaining: 3m 7s\n",
      "107:\tlearn: 0.0099168\ttotal: 22.8s\tremaining: 3m 8s\n",
      "108:\tlearn: 0.0098815\ttotal: 23.1s\tremaining: 3m 8s\n",
      "109:\tlearn: 0.0098484\ttotal: 23.3s\tremaining: 3m 8s\n",
      "110:\tlearn: 0.0098186\ttotal: 23.6s\tremaining: 3m 8s\n",
      "111:\tlearn: 0.0097884\ttotal: 23.8s\tremaining: 3m 8s\n",
      "112:\tlearn: 0.0097781\ttotal: 24s\tremaining: 3m 8s\n",
      "113:\tlearn: 0.0097601\ttotal: 24.2s\tremaining: 3m 7s\n",
      "114:\tlearn: 0.0097454\ttotal: 24.3s\tremaining: 3m 7s\n",
      "115:\tlearn: 0.0097145\ttotal: 24.5s\tremaining: 3m 6s\n",
      "116:\tlearn: 0.0096835\ttotal: 24.7s\tremaining: 3m 6s\n",
      "117:\tlearn: 0.0096677\ttotal: 24.9s\tremaining: 3m 6s\n",
      "118:\tlearn: 0.0096453\ttotal: 25.1s\tremaining: 3m 5s\n",
      "119:\tlearn: 0.0096323\ttotal: 25.2s\tremaining: 3m 4s\n",
      "120:\tlearn: 0.0096001\ttotal: 25.4s\tremaining: 3m 4s\n",
      "121:\tlearn: 0.0095617\ttotal: 25.6s\tremaining: 3m 4s\n",
      "122:\tlearn: 0.0095415\ttotal: 25.8s\tremaining: 3m 4s\n",
      "123:\tlearn: 0.0095066\ttotal: 26s\tremaining: 3m 3s\n",
      "124:\tlearn: 0.0094787\ttotal: 26.2s\tremaining: 3m 3s\n",
      "125:\tlearn: 0.0094687\ttotal: 26.5s\tremaining: 3m 3s\n",
      "126:\tlearn: 0.0094588\ttotal: 26.8s\tremaining: 3m 3s\n",
      "127:\tlearn: 0.0094419\ttotal: 27s\tremaining: 3m 3s\n",
      "128:\tlearn: 0.0094210\ttotal: 27.3s\tremaining: 3m 4s\n",
      "129:\tlearn: 0.0094028\ttotal: 27.5s\tremaining: 3m 4s\n",
      "130:\tlearn: 0.0093763\ttotal: 28s\tremaining: 3m 5s\n",
      "131:\tlearn: 0.0093673\ttotal: 28.2s\tremaining: 3m 5s\n",
      "132:\tlearn: 0.0093404\ttotal: 28.3s\tremaining: 3m 4s\n",
      "133:\tlearn: 0.0093332\ttotal: 28.5s\tremaining: 3m 4s\n",
      "134:\tlearn: 0.0093260\ttotal: 28.7s\tremaining: 3m 3s\n",
      "135:\tlearn: 0.0093195\ttotal: 28.8s\tremaining: 3m 3s\n",
      "136:\tlearn: 0.0092943\ttotal: 29s\tremaining: 3m 2s\n",
      "137:\tlearn: 0.0092844\ttotal: 29.2s\tremaining: 3m 2s\n",
      "138:\tlearn: 0.0092696\ttotal: 29.4s\tremaining: 3m 1s\n",
      "139:\tlearn: 0.0092608\ttotal: 29.6s\tremaining: 3m 1s\n",
      "140:\tlearn: 0.0092555\ttotal: 29.9s\tremaining: 3m 2s\n",
      "141:\tlearn: 0.0092417\ttotal: 30.1s\tremaining: 3m 2s\n",
      "142:\tlearn: 0.0092219\ttotal: 30.5s\tremaining: 3m 2s\n",
      "143:\tlearn: 0.0092076\ttotal: 30.8s\tremaining: 3m 3s\n",
      "144:\tlearn: 0.0091898\ttotal: 31.2s\tremaining: 3m 3s\n",
      "145:\tlearn: 0.0091862\ttotal: 31.3s\tremaining: 3m 3s\n",
      "146:\tlearn: 0.0091678\ttotal: 31.5s\tremaining: 3m 3s\n",
      "147:\tlearn: 0.0091633\ttotal: 31.7s\tremaining: 3m 2s\n",
      "148:\tlearn: 0.0091502\ttotal: 31.9s\tremaining: 3m 2s\n",
      "149:\tlearn: 0.0091465\ttotal: 32.1s\tremaining: 3m 1s\n",
      "150:\tlearn: 0.0091360\ttotal: 32.4s\tremaining: 3m 2s\n",
      "151:\tlearn: 0.0091229\ttotal: 32.6s\tremaining: 3m 2s\n",
      "152:\tlearn: 0.0091186\ttotal: 32.8s\tremaining: 3m 1s\n",
      "153:\tlearn: 0.0091157\ttotal: 33s\tremaining: 3m 1s\n",
      "154:\tlearn: 0.0091065\ttotal: 33.2s\tremaining: 3m\n",
      "155:\tlearn: 0.0090937\ttotal: 33.5s\tremaining: 3m\n",
      "156:\tlearn: 0.0090914\ttotal: 33.7s\tremaining: 3m\n",
      "157:\tlearn: 0.0090883\ttotal: 33.8s\tremaining: 3m\n",
      "158:\tlearn: 0.0090747\ttotal: 34s\tremaining: 3m\n",
      "159:\tlearn: 0.0090719\ttotal: 34.2s\tremaining: 2m 59s\n",
      "160:\tlearn: 0.0090693\ttotal: 34.5s\tremaining: 2m 59s\n",
      "161:\tlearn: 0.0090668\ttotal: 34.7s\tremaining: 2m 59s\n",
      "162:\tlearn: 0.0090594\ttotal: 34.9s\tremaining: 2m 59s\n",
      "163:\tlearn: 0.0090578\ttotal: 35.1s\tremaining: 2m 58s\n",
      "164:\tlearn: 0.0090490\ttotal: 35.3s\tremaining: 2m 58s\n",
      "165:\tlearn: 0.0090358\ttotal: 35.5s\tremaining: 2m 58s\n",
      "166:\tlearn: 0.0090305\ttotal: 35.7s\tremaining: 2m 57s\n",
      "167:\tlearn: 0.0090179\ttotal: 35.9s\tremaining: 2m 57s\n",
      "168:\tlearn: 0.0090136\ttotal: 36s\tremaining: 2m 57s\n",
      "169:\tlearn: 0.0090115\ttotal: 36.2s\tremaining: 2m 56s\n",
      "170:\tlearn: 0.0089950\ttotal: 36.4s\tremaining: 2m 56s\n",
      "171:\tlearn: 0.0089933\ttotal: 36.6s\tremaining: 2m 56s\n",
      "172:\tlearn: 0.0089921\ttotal: 36.8s\tremaining: 2m 55s\n",
      "173:\tlearn: 0.0089814\ttotal: 36.9s\tremaining: 2m 55s\n",
      "174:\tlearn: 0.0089798\ttotal: 37.1s\tremaining: 2m 54s\n",
      "175:\tlearn: 0.0089755\ttotal: 37.3s\tremaining: 2m 54s\n",
      "176:\tlearn: 0.0089696\ttotal: 37.5s\tremaining: 2m 54s\n",
      "177:\tlearn: 0.0089662\ttotal: 37.7s\tremaining: 2m 54s\n",
      "178:\tlearn: 0.0089618\ttotal: 37.9s\tremaining: 2m 53s\n",
      "179:\tlearn: 0.0089572\ttotal: 38s\tremaining: 2m 53s\n",
      "180:\tlearn: 0.0089557\ttotal: 38.2s\tremaining: 2m 52s\n",
      "181:\tlearn: 0.0089545\ttotal: 38.4s\tremaining: 2m 52s\n",
      "182:\tlearn: 0.0089536\ttotal: 38.6s\tremaining: 2m 52s\n",
      "183:\tlearn: 0.0089510\ttotal: 38.7s\tremaining: 2m 51s\n",
      "184:\tlearn: 0.0089504\ttotal: 38.9s\tremaining: 2m 51s\n",
      "185:\tlearn: 0.0089392\ttotal: 39.1s\tremaining: 2m 51s\n",
      "186:\tlearn: 0.0089350\ttotal: 39.3s\tremaining: 2m 50s\n",
      "187:\tlearn: 0.0089300\ttotal: 39.5s\tremaining: 2m 50s\n",
      "188:\tlearn: 0.0089289\ttotal: 39.7s\tremaining: 2m 50s\n",
      "189:\tlearn: 0.0089268\ttotal: 39.8s\tremaining: 2m 49s\n",
      "190:\tlearn: 0.0089067\ttotal: 40s\tremaining: 2m 49s\n",
      "191:\tlearn: 0.0089005\ttotal: 40.2s\tremaining: 2m 49s\n",
      "192:\tlearn: 0.0088925\ttotal: 40.4s\tremaining: 2m 49s\n",
      "193:\tlearn: 0.0088873\ttotal: 40.6s\tremaining: 2m 48s\n",
      "194:\tlearn: 0.0088815\ttotal: 40.8s\tremaining: 2m 48s\n",
      "195:\tlearn: 0.0088748\ttotal: 41s\tremaining: 2m 47s\n",
      "196:\tlearn: 0.0088662\ttotal: 41.1s\tremaining: 2m 47s\n",
      "197:\tlearn: 0.0088615\ttotal: 41.3s\tremaining: 2m 47s\n",
      "198:\tlearn: 0.0088598\ttotal: 41.5s\tremaining: 2m 47s\n",
      "199:\tlearn: 0.0088576\ttotal: 41.7s\tremaining: 2m 46s\n",
      "200:\tlearn: 0.0088493\ttotal: 41.9s\tremaining: 2m 46s\n",
      "201:\tlearn: 0.0088402\ttotal: 42.1s\tremaining: 2m 46s\n",
      "202:\tlearn: 0.0088367\ttotal: 42.3s\tremaining: 2m 46s\n",
      "203:\tlearn: 0.0088360\ttotal: 42.5s\tremaining: 2m 45s\n",
      "204:\tlearn: 0.0088351\ttotal: 42.7s\tremaining: 2m 45s\n",
      "205:\tlearn: 0.0088315\ttotal: 42.8s\tremaining: 2m 45s\n",
      "206:\tlearn: 0.0088276\ttotal: 43s\tremaining: 2m 44s\n",
      "207:\tlearn: 0.0088233\ttotal: 43.2s\tremaining: 2m 44s\n",
      "208:\tlearn: 0.0088229\ttotal: 43.4s\tremaining: 2m 44s\n",
      "209:\tlearn: 0.0088217\ttotal: 43.7s\tremaining: 2m 44s\n",
      "210:\tlearn: 0.0088196\ttotal: 44s\tremaining: 2m 44s\n",
      "211:\tlearn: 0.0088192\ttotal: 44.2s\tremaining: 2m 44s\n",
      "212:\tlearn: 0.0088137\ttotal: 44.4s\tremaining: 2m 44s\n",
      "213:\tlearn: 0.0088131\ttotal: 44.6s\tremaining: 2m 43s\n",
      "214:\tlearn: 0.0088048\ttotal: 44.8s\tremaining: 2m 43s\n",
      "215:\tlearn: 0.0087986\ttotal: 45s\tremaining: 2m 43s\n",
      "216:\tlearn: 0.0087962\ttotal: 45.2s\tremaining: 2m 43s\n",
      "217:\tlearn: 0.0087954\ttotal: 45.4s\tremaining: 2m 42s\n",
      "218:\tlearn: 0.0087905\ttotal: 45.6s\tremaining: 2m 42s\n",
      "219:\tlearn: 0.0087827\ttotal: 45.8s\tremaining: 2m 42s\n",
      "220:\tlearn: 0.0087818\ttotal: 46s\tremaining: 2m 41s\n",
      "221:\tlearn: 0.0087684\ttotal: 46.2s\tremaining: 2m 41s\n",
      "222:\tlearn: 0.0087667\ttotal: 46.3s\tremaining: 2m 41s\n",
      "223:\tlearn: 0.0087623\ttotal: 46.5s\tremaining: 2m 41s\n",
      "224:\tlearn: 0.0087561\ttotal: 46.7s\tremaining: 2m 40s\n",
      "225:\tlearn: 0.0087555\ttotal: 46.9s\tremaining: 2m 40s\n",
      "226:\tlearn: 0.0087519\ttotal: 47.1s\tremaining: 2m 40s\n",
      "227:\tlearn: 0.0087502\ttotal: 47.3s\tremaining: 2m 40s\n",
      "228:\tlearn: 0.0087498\ttotal: 47.5s\tremaining: 2m 39s\n",
      "229:\tlearn: 0.0087369\ttotal: 47.7s\tremaining: 2m 39s\n",
      "230:\tlearn: 0.0087328\ttotal: 47.9s\tremaining: 2m 39s\n",
      "231:\tlearn: 0.0087319\ttotal: 48s\tremaining: 2m 39s\n",
      "232:\tlearn: 0.0087280\ttotal: 48.2s\tremaining: 2m 38s\n",
      "233:\tlearn: 0.0087277\ttotal: 48.4s\tremaining: 2m 38s\n",
      "234:\tlearn: 0.0087227\ttotal: 48.6s\tremaining: 2m 38s\n",
      "235:\tlearn: 0.0087188\ttotal: 48.8s\tremaining: 2m 37s\n",
      "236:\tlearn: 0.0087178\ttotal: 49s\tremaining: 2m 37s\n",
      "237:\tlearn: 0.0087166\ttotal: 49.2s\tremaining: 2m 37s\n",
      "238:\tlearn: 0.0087141\ttotal: 49.4s\tremaining: 2m 37s\n",
      "239:\tlearn: 0.0087108\ttotal: 49.6s\tremaining: 2m 36s\n",
      "240:\tlearn: 0.0087098\ttotal: 49.7s\tremaining: 2m 36s\n",
      "241:\tlearn: 0.0087083\ttotal: 49.9s\tremaining: 2m 36s\n",
      "242:\tlearn: 0.0087046\ttotal: 50.2s\tremaining: 2m 36s\n",
      "243:\tlearn: 0.0087034\ttotal: 50.4s\tremaining: 2m 36s\n",
      "244:\tlearn: 0.0087014\ttotal: 50.6s\tremaining: 2m 35s\n",
      "245:\tlearn: 0.0086966\ttotal: 50.8s\tremaining: 2m 35s\n",
      "246:\tlearn: 0.0086964\ttotal: 51s\tremaining: 2m 35s\n",
      "247:\tlearn: 0.0086951\ttotal: 51.2s\tremaining: 2m 35s\n",
      "248:\tlearn: 0.0086902\ttotal: 51.4s\tremaining: 2m 35s\n",
      "249:\tlearn: 0.0086876\ttotal: 51.6s\tremaining: 2m 34s\n",
      "250:\tlearn: 0.0086837\ttotal: 51.8s\tremaining: 2m 34s\n",
      "251:\tlearn: 0.0086800\ttotal: 52s\tremaining: 2m 34s\n",
      "252:\tlearn: 0.0086767\ttotal: 52.2s\tremaining: 2m 34s\n",
      "253:\tlearn: 0.0086752\ttotal: 52.4s\tremaining: 2m 33s\n",
      "254:\tlearn: 0.0086733\ttotal: 52.6s\tremaining: 2m 33s\n",
      "255:\tlearn: 0.0086687\ttotal: 52.8s\tremaining: 2m 33s\n",
      "256:\tlearn: 0.0086676\ttotal: 53s\tremaining: 2m 33s\n",
      "257:\tlearn: 0.0086565\ttotal: 53.2s\tremaining: 2m 32s\n",
      "258:\tlearn: 0.0086542\ttotal: 53.4s\tremaining: 2m 32s\n",
      "259:\tlearn: 0.0086512\ttotal: 53.5s\tremaining: 2m 32s\n",
      "260:\tlearn: 0.0086509\ttotal: 53.7s\tremaining: 2m 32s\n",
      "261:\tlearn: 0.0086481\ttotal: 53.9s\tremaining: 2m 31s\n",
      "262:\tlearn: 0.0086455\ttotal: 54.1s\tremaining: 2m 31s\n",
      "263:\tlearn: 0.0086413\ttotal: 54.3s\tremaining: 2m 31s\n",
      "264:\tlearn: 0.0086406\ttotal: 54.5s\tremaining: 2m 31s\n",
      "265:\tlearn: 0.0086396\ttotal: 54.7s\tremaining: 2m 30s\n",
      "266:\tlearn: 0.0086390\ttotal: 54.9s\tremaining: 2m 30s\n",
      "267:\tlearn: 0.0086283\ttotal: 55s\tremaining: 2m 30s\n",
      "268:\tlearn: 0.0086228\ttotal: 55.3s\tremaining: 2m 30s\n",
      "269:\tlearn: 0.0086187\ttotal: 55.4s\tremaining: 2m 29s\n",
      "270:\tlearn: 0.0086181\ttotal: 55.6s\tremaining: 2m 29s\n",
      "271:\tlearn: 0.0086176\ttotal: 55.8s\tremaining: 2m 29s\n",
      "272:\tlearn: 0.0086159\ttotal: 56s\tremaining: 2m 29s\n",
      "273:\tlearn: 0.0086126\ttotal: 56.2s\tremaining: 2m 28s\n",
      "274:\tlearn: 0.0086091\ttotal: 56.5s\tremaining: 2m 28s\n",
      "275:\tlearn: 0.0086073\ttotal: 56.7s\tremaining: 2m 28s\n",
      "276:\tlearn: 0.0086069\ttotal: 56.9s\tremaining: 2m 28s\n",
      "277:\tlearn: 0.0086062\ttotal: 57.1s\tremaining: 2m 28s\n",
      "278:\tlearn: 0.0086043\ttotal: 57.2s\tremaining: 2m 27s\n",
      "279:\tlearn: 0.0086029\ttotal: 57.4s\tremaining: 2m 27s\n",
      "280:\tlearn: 0.0085945\ttotal: 57.6s\tremaining: 2m 27s\n",
      "281:\tlearn: 0.0085924\ttotal: 57.8s\tremaining: 2m 27s\n",
      "282:\tlearn: 0.0085908\ttotal: 58s\tremaining: 2m 27s\n",
      "283:\tlearn: 0.0085903\ttotal: 58.3s\tremaining: 2m 26s\n",
      "284:\tlearn: 0.0085888\ttotal: 58.5s\tremaining: 2m 26s\n",
      "285:\tlearn: 0.0085871\ttotal: 58.6s\tremaining: 2m 26s\n",
      "286:\tlearn: 0.0085866\ttotal: 58.8s\tremaining: 2m 26s\n",
      "287:\tlearn: 0.0085850\ttotal: 59s\tremaining: 2m 25s\n",
      "288:\tlearn: 0.0085842\ttotal: 59.2s\tremaining: 2m 25s\n",
      "289:\tlearn: 0.0085829\ttotal: 59.4s\tremaining: 2m 25s\n",
      "290:\tlearn: 0.0085818\ttotal: 59.7s\tremaining: 2m 25s\n",
      "291:\tlearn: 0.0085787\ttotal: 59.9s\tremaining: 2m 25s\n",
      "292:\tlearn: 0.0085777\ttotal: 1m\tremaining: 2m 25s\n",
      "293:\tlearn: 0.0085763\ttotal: 1m\tremaining: 2m 24s\n",
      "294:\tlearn: 0.0085759\ttotal: 1m\tremaining: 2m 24s\n",
      "295:\tlearn: 0.0085739\ttotal: 1m\tremaining: 2m 24s\n",
      "296:\tlearn: 0.0085697\ttotal: 1m\tremaining: 2m 24s\n",
      "297:\tlearn: 0.0085694\ttotal: 1m 1s\tremaining: 2m 23s\n",
      "298:\tlearn: 0.0085692\ttotal: 1m 1s\tremaining: 2m 23s\n",
      "299:\tlearn: 0.0085677\ttotal: 1m 1s\tremaining: 2m 23s\n",
      "300:\tlearn: 0.0085666\ttotal: 1m 1s\tremaining: 2m 23s\n",
      "301:\tlearn: 0.0085664\ttotal: 1m 1s\tremaining: 2m 22s\n",
      "302:\tlearn: 0.0085661\ttotal: 1m 2s\tremaining: 2m 22s\n",
      "303:\tlearn: 0.0085658\ttotal: 1m 2s\tremaining: 2m 22s\n",
      "304:\tlearn: 0.0085640\ttotal: 1m 2s\tremaining: 2m 22s\n",
      "305:\tlearn: 0.0085627\ttotal: 1m 2s\tremaining: 2m 22s\n",
      "306:\tlearn: 0.0085615\ttotal: 1m 2s\tremaining: 2m 21s\n",
      "307:\tlearn: 0.0085602\ttotal: 1m 3s\tremaining: 2m 21s\n",
      "308:\tlearn: 0.0085593\ttotal: 1m 3s\tremaining: 2m 21s\n",
      "309:\tlearn: 0.0085590\ttotal: 1m 3s\tremaining: 2m 21s\n",
      "310:\tlearn: 0.0085586\ttotal: 1m 3s\tremaining: 2m 21s\n",
      "311:\tlearn: 0.0085579\ttotal: 1m 3s\tremaining: 2m 20s\n",
      "312:\tlearn: 0.0085554\ttotal: 1m 4s\tremaining: 2m 20s\n",
      "313:\tlearn: 0.0085535\ttotal: 1m 4s\tremaining: 2m 20s\n",
      "314:\tlearn: 0.0085522\ttotal: 1m 4s\tremaining: 2m 20s\n",
      "315:\tlearn: 0.0085498\ttotal: 1m 4s\tremaining: 2m 19s\n",
      "316:\tlearn: 0.0085486\ttotal: 1m 4s\tremaining: 2m 19s\n",
      "317:\tlearn: 0.0085485\ttotal: 1m 4s\tremaining: 2m 19s\n",
      "318:\tlearn: 0.0085482\ttotal: 1m 5s\tremaining: 2m 19s\n",
      "319:\tlearn: 0.0085460\ttotal: 1m 5s\tremaining: 2m 18s\n",
      "320:\tlearn: 0.0085452\ttotal: 1m 5s\tremaining: 2m 18s\n",
      "321:\tlearn: 0.0085443\ttotal: 1m 5s\tremaining: 2m 18s\n",
      "322:\tlearn: 0.0085430\ttotal: 1m 5s\tremaining: 2m 18s\n",
      "323:\tlearn: 0.0085427\ttotal: 1m 6s\tremaining: 2m 18s\n",
      "324:\tlearn: 0.0085403\ttotal: 1m 6s\tremaining: 2m 17s\n",
      "325:\tlearn: 0.0085400\ttotal: 1m 6s\tremaining: 2m 17s\n",
      "326:\tlearn: 0.0085398\ttotal: 1m 6s\tremaining: 2m 17s\n",
      "327:\tlearn: 0.0085396\ttotal: 1m 7s\tremaining: 2m 17s\n",
      "328:\tlearn: 0.0085377\ttotal: 1m 7s\tremaining: 2m 17s\n",
      "329:\tlearn: 0.0085370\ttotal: 1m 7s\tremaining: 2m 16s\n",
      "330:\tlearn: 0.0085358\ttotal: 1m 7s\tremaining: 2m 16s\n",
      "331:\tlearn: 0.0085355\ttotal: 1m 7s\tremaining: 2m 16s\n",
      "332:\tlearn: 0.0085346\ttotal: 1m 8s\tremaining: 2m 16s\n",
      "333:\tlearn: 0.0085335\ttotal: 1m 8s\tremaining: 2m 16s\n",
      "334:\tlearn: 0.0085326\ttotal: 1m 8s\tremaining: 2m 15s\n",
      "335:\tlearn: 0.0085259\ttotal: 1m 8s\tremaining: 2m 15s\n",
      "336:\tlearn: 0.0085257\ttotal: 1m 8s\tremaining: 2m 15s\n",
      "337:\tlearn: 0.0085250\ttotal: 1m 9s\tremaining: 2m 15s\n",
      "338:\tlearn: 0.0085239\ttotal: 1m 9s\tremaining: 2m 15s\n",
      "339:\tlearn: 0.0085238\ttotal: 1m 9s\tremaining: 2m 15s\n",
      "340:\tlearn: 0.0085218\ttotal: 1m 9s\tremaining: 2m 14s\n",
      "341:\tlearn: 0.0085216\ttotal: 1m 9s\tremaining: 2m 14s\n",
      "342:\tlearn: 0.0085215\ttotal: 1m 10s\tremaining: 2m 14s\n",
      "343:\tlearn: 0.0085198\ttotal: 1m 10s\tremaining: 2m 14s\n",
      "344:\tlearn: 0.0085185\ttotal: 1m 10s\tremaining: 2m 13s\n",
      "345:\tlearn: 0.0085179\ttotal: 1m 10s\tremaining: 2m 13s\n",
      "346:\tlearn: 0.0085177\ttotal: 1m 10s\tremaining: 2m 13s\n",
      "347:\tlearn: 0.0085172\ttotal: 1m 11s\tremaining: 2m 13s\n",
      "348:\tlearn: 0.0085169\ttotal: 1m 11s\tremaining: 2m 12s\n",
      "349:\tlearn: 0.0085168\ttotal: 1m 11s\tremaining: 2m 12s\n",
      "350:\tlearn: 0.0085166\ttotal: 1m 11s\tremaining: 2m 12s\n",
      "351:\tlearn: 0.0085163\ttotal: 1m 11s\tremaining: 2m 12s\n",
      "352:\tlearn: 0.0085151\ttotal: 1m 12s\tremaining: 2m 11s\n",
      "353:\tlearn: 0.0085144\ttotal: 1m 12s\tremaining: 2m 11s\n",
      "354:\tlearn: 0.0085130\ttotal: 1m 12s\tremaining: 2m 11s\n",
      "355:\tlearn: 0.0085074\ttotal: 1m 12s\tremaining: 2m 11s\n",
      "356:\tlearn: 0.0085072\ttotal: 1m 12s\tremaining: 2m 11s\n",
      "357:\tlearn: 0.0085066\ttotal: 1m 12s\tremaining: 2m 10s\n",
      "358:\tlearn: 0.0085041\ttotal: 1m 13s\tremaining: 2m 10s\n",
      "359:\tlearn: 0.0085027\ttotal: 1m 13s\tremaining: 2m 10s\n",
      "360:\tlearn: 0.0085026\ttotal: 1m 13s\tremaining: 2m 10s\n",
      "361:\tlearn: 0.0085019\ttotal: 1m 13s\tremaining: 2m 9s\n",
      "362:\tlearn: 0.0085018\ttotal: 1m 13s\tremaining: 2m 9s\n",
      "363:\tlearn: 0.0085008\ttotal: 1m 14s\tremaining: 2m 9s\n",
      "364:\tlearn: 0.0085002\ttotal: 1m 14s\tremaining: 2m 9s\n",
      "365:\tlearn: 0.0084983\ttotal: 1m 14s\tremaining: 2m 8s\n",
      "366:\tlearn: 0.0084969\ttotal: 1m 14s\tremaining: 2m 8s\n",
      "367:\tlearn: 0.0084961\ttotal: 1m 14s\tremaining: 2m 8s\n",
      "368:\tlearn: 0.0084956\ttotal: 1m 15s\tremaining: 2m 8s\n",
      "369:\tlearn: 0.0084947\ttotal: 1m 15s\tremaining: 2m 8s\n",
      "370:\tlearn: 0.0084945\ttotal: 1m 15s\tremaining: 2m 7s\n",
      "371:\tlearn: 0.0084939\ttotal: 1m 15s\tremaining: 2m 7s\n",
      "372:\tlearn: 0.0084919\ttotal: 1m 15s\tremaining: 2m 7s\n",
      "373:\tlearn: 0.0084918\ttotal: 1m 16s\tremaining: 2m 7s\n",
      "374:\tlearn: 0.0084907\ttotal: 1m 16s\tremaining: 2m 7s\n",
      "375:\tlearn: 0.0084887\ttotal: 1m 16s\tremaining: 2m 6s\n",
      "376:\tlearn: 0.0084874\ttotal: 1m 16s\tremaining: 2m 6s\n",
      "377:\tlearn: 0.0084867\ttotal: 1m 16s\tremaining: 2m 6s\n",
      "378:\tlearn: 0.0084817\ttotal: 1m 17s\tremaining: 2m 6s\n",
      "379:\tlearn: 0.0084815\ttotal: 1m 17s\tremaining: 2m 6s\n",
      "380:\tlearn: 0.0084814\ttotal: 1m 17s\tremaining: 2m 5s\n",
      "381:\tlearn: 0.0084806\ttotal: 1m 17s\tremaining: 2m 5s\n",
      "382:\tlearn: 0.0084797\ttotal: 1m 17s\tremaining: 2m 5s\n",
      "383:\tlearn: 0.0084752\ttotal: 1m 18s\tremaining: 2m 5s\n",
      "384:\tlearn: 0.0084751\ttotal: 1m 18s\tremaining: 2m 5s\n",
      "385:\tlearn: 0.0084732\ttotal: 1m 18s\tremaining: 2m 4s\n",
      "386:\tlearn: 0.0084729\ttotal: 1m 18s\tremaining: 2m 4s\n",
      "387:\tlearn: 0.0084729\ttotal: 1m 18s\tremaining: 2m 4s\n",
      "388:\tlearn: 0.0084723\ttotal: 1m 18s\tremaining: 2m 4s\n",
      "389:\tlearn: 0.0084719\ttotal: 1m 19s\tremaining: 2m 3s\n",
      "390:\tlearn: 0.0084713\ttotal: 1m 19s\tremaining: 2m 3s\n",
      "391:\tlearn: 0.0084708\ttotal: 1m 19s\tremaining: 2m 3s\n",
      "392:\tlearn: 0.0084707\ttotal: 1m 19s\tremaining: 2m 3s\n",
      "393:\tlearn: 0.0084695\ttotal: 1m 19s\tremaining: 2m 3s\n",
      "394:\tlearn: 0.0084683\ttotal: 1m 20s\tremaining: 2m 2s\n",
      "395:\tlearn: 0.0084678\ttotal: 1m 20s\tremaining: 2m 2s\n",
      "396:\tlearn: 0.0084676\ttotal: 1m 20s\tremaining: 2m 2s\n",
      "397:\tlearn: 0.0084676\ttotal: 1m 20s\tremaining: 2m 2s\n",
      "398:\tlearn: 0.0084668\ttotal: 1m 20s\tremaining: 2m 1s\n",
      "399:\tlearn: 0.0084662\ttotal: 1m 21s\tremaining: 2m 1s\n",
      "400:\tlearn: 0.0084661\ttotal: 1m 21s\tremaining: 2m 1s\n",
      "401:\tlearn: 0.0084657\ttotal: 1m 21s\tremaining: 2m 1s\n",
      "402:\tlearn: 0.0084645\ttotal: 1m 21s\tremaining: 2m 1s\n",
      "403:\tlearn: 0.0084642\ttotal: 1m 21s\tremaining: 2m\n",
      "404:\tlearn: 0.0084634\ttotal: 1m 22s\tremaining: 2m\n",
      "405:\tlearn: 0.0084634\ttotal: 1m 22s\tremaining: 2m\n",
      "406:\tlearn: 0.0084626\ttotal: 1m 22s\tremaining: 2m\n",
      "407:\tlearn: 0.0084622\ttotal: 1m 22s\tremaining: 2m\n",
      "408:\tlearn: 0.0084617\ttotal: 1m 23s\tremaining: 2m\n",
      "409:\tlearn: 0.0084604\ttotal: 1m 23s\tremaining: 1m 59s\n",
      "410:\tlearn: 0.0084567\ttotal: 1m 23s\tremaining: 1m 59s\n",
      "411:\tlearn: 0.0084550\ttotal: 1m 23s\tremaining: 1m 59s\n",
      "412:\tlearn: 0.0084541\ttotal: 1m 23s\tremaining: 1m 59s\n",
      "413:\tlearn: 0.0084535\ttotal: 1m 24s\tremaining: 1m 59s\n",
      "414:\tlearn: 0.0084534\ttotal: 1m 24s\tremaining: 1m 58s\n",
      "415:\tlearn: 0.0084533\ttotal: 1m 24s\tremaining: 1m 58s\n",
      "416:\tlearn: 0.0084529\ttotal: 1m 24s\tremaining: 1m 58s\n",
      "417:\tlearn: 0.0084522\ttotal: 1m 24s\tremaining: 1m 58s\n",
      "418:\tlearn: 0.0084515\ttotal: 1m 25s\tremaining: 1m 57s\n",
      "419:\tlearn: 0.0084505\ttotal: 1m 25s\tremaining: 1m 57s\n",
      "420:\tlearn: 0.0084501\ttotal: 1m 25s\tremaining: 1m 57s\n",
      "421:\tlearn: 0.0084501\ttotal: 1m 25s\tremaining: 1m 57s\n",
      "422:\tlearn: 0.0084499\ttotal: 1m 25s\tremaining: 1m 57s\n",
      "423:\tlearn: 0.0084498\ttotal: 1m 26s\tremaining: 1m 56s\n",
      "424:\tlearn: 0.0084489\ttotal: 1m 26s\tremaining: 1m 56s\n",
      "425:\tlearn: 0.0084485\ttotal: 1m 26s\tremaining: 1m 56s\n",
      "426:\tlearn: 0.0084477\ttotal: 1m 26s\tremaining: 1m 56s\n",
      "427:\tlearn: 0.0084471\ttotal: 1m 26s\tremaining: 1m 56s\n",
      "428:\tlearn: 0.0084468\ttotal: 1m 27s\tremaining: 1m 55s\n",
      "429:\tlearn: 0.0084464\ttotal: 1m 27s\tremaining: 1m 55s\n",
      "430:\tlearn: 0.0084459\ttotal: 1m 27s\tremaining: 1m 55s\n",
      "431:\tlearn: 0.0084447\ttotal: 1m 27s\tremaining: 1m 55s\n",
      "432:\tlearn: 0.0084445\ttotal: 1m 27s\tremaining: 1m 55s\n",
      "433:\tlearn: 0.0084444\ttotal: 1m 28s\tremaining: 1m 54s\n",
      "434:\tlearn: 0.0084442\ttotal: 1m 28s\tremaining: 1m 54s\n",
      "435:\tlearn: 0.0084438\ttotal: 1m 28s\tremaining: 1m 54s\n",
      "436:\tlearn: 0.0084425\ttotal: 1m 28s\tremaining: 1m 54s\n",
      "437:\tlearn: 0.0084420\ttotal: 1m 28s\tremaining: 1m 54s\n",
      "438:\tlearn: 0.0084419\ttotal: 1m 29s\tremaining: 1m 53s\n",
      "439:\tlearn: 0.0084419\ttotal: 1m 29s\tremaining: 1m 53s\n",
      "440:\tlearn: 0.0084418\ttotal: 1m 29s\tremaining: 1m 53s\n",
      "441:\tlearn: 0.0084415\ttotal: 1m 29s\tremaining: 1m 53s\n",
      "442:\tlearn: 0.0084414\ttotal: 1m 29s\tremaining: 1m 52s\n",
      "443:\tlearn: 0.0084408\ttotal: 1m 30s\tremaining: 1m 52s\n",
      "444:\tlearn: 0.0084403\ttotal: 1m 30s\tremaining: 1m 52s\n",
      "445:\tlearn: 0.0084398\ttotal: 1m 30s\tremaining: 1m 52s\n",
      "446:\tlearn: 0.0084394\ttotal: 1m 30s\tremaining: 1m 52s\n",
      "447:\tlearn: 0.0084390\ttotal: 1m 30s\tremaining: 1m 52s\n",
      "448:\tlearn: 0.0084384\ttotal: 1m 31s\tremaining: 1m 51s\n",
      "449:\tlearn: 0.0084379\ttotal: 1m 31s\tremaining: 1m 51s\n",
      "450:\tlearn: 0.0084376\ttotal: 1m 31s\tremaining: 1m 51s\n",
      "451:\tlearn: 0.0084375\ttotal: 1m 31s\tremaining: 1m 51s\n",
      "452:\tlearn: 0.0084375\ttotal: 1m 32s\tremaining: 1m 51s\n",
      "453:\tlearn: 0.0084374\ttotal: 1m 32s\tremaining: 1m 50s\n",
      "454:\tlearn: 0.0084373\ttotal: 1m 32s\tremaining: 1m 50s\n",
      "455:\tlearn: 0.0084370\ttotal: 1m 32s\tremaining: 1m 50s\n",
      "456:\tlearn: 0.0084366\ttotal: 1m 32s\tremaining: 1m 50s\n",
      "457:\tlearn: 0.0084365\ttotal: 1m 33s\tremaining: 1m 50s\n",
      "458:\tlearn: 0.0084361\ttotal: 1m 33s\tremaining: 1m 50s\n",
      "459:\tlearn: 0.0084352\ttotal: 1m 33s\tremaining: 1m 49s\n",
      "460:\tlearn: 0.0084337\ttotal: 1m 33s\tremaining: 1m 49s\n",
      "461:\tlearn: 0.0084333\ttotal: 1m 33s\tremaining: 1m 49s\n",
      "462:\tlearn: 0.0084330\ttotal: 1m 34s\tremaining: 1m 49s\n",
      "463:\tlearn: 0.0084322\ttotal: 1m 34s\tremaining: 1m 49s\n",
      "464:\tlearn: 0.0084317\ttotal: 1m 34s\tremaining: 1m 48s\n",
      "465:\tlearn: 0.0084308\ttotal: 1m 34s\tremaining: 1m 48s\n",
      "466:\tlearn: 0.0084305\ttotal: 1m 35s\tremaining: 1m 48s\n",
      "467:\tlearn: 0.0084298\ttotal: 1m 35s\tremaining: 1m 48s\n",
      "468:\tlearn: 0.0084295\ttotal: 1m 35s\tremaining: 1m 48s\n",
      "469:\tlearn: 0.0084291\ttotal: 1m 35s\tremaining: 1m 48s\n",
      "470:\tlearn: 0.0084287\ttotal: 1m 35s\tremaining: 1m 47s\n",
      "471:\tlearn: 0.0084275\ttotal: 1m 36s\tremaining: 1m 47s\n",
      "472:\tlearn: 0.0084275\ttotal: 1m 36s\tremaining: 1m 47s\n",
      "473:\tlearn: 0.0084271\ttotal: 1m 36s\tremaining: 1m 47s\n",
      "474:\tlearn: 0.0084268\ttotal: 1m 36s\tremaining: 1m 46s\n",
      "475:\tlearn: 0.0084265\ttotal: 1m 36s\tremaining: 1m 46s\n",
      "476:\tlearn: 0.0084264\ttotal: 1m 37s\tremaining: 1m 46s\n",
      "477:\tlearn: 0.0084260\ttotal: 1m 37s\tremaining: 1m 46s\n",
      "478:\tlearn: 0.0084258\ttotal: 1m 37s\tremaining: 1m 46s\n",
      "479:\tlearn: 0.0084249\ttotal: 1m 37s\tremaining: 1m 45s\n",
      "480:\tlearn: 0.0084245\ttotal: 1m 37s\tremaining: 1m 45s\n",
      "481:\tlearn: 0.0084244\ttotal: 1m 38s\tremaining: 1m 45s\n",
      "482:\tlearn: 0.0084212\ttotal: 1m 38s\tremaining: 1m 45s\n",
      "483:\tlearn: 0.0084209\ttotal: 1m 38s\tremaining: 1m 45s\n",
      "484:\tlearn: 0.0084207\ttotal: 1m 38s\tremaining: 1m 44s\n",
      "485:\tlearn: 0.0084205\ttotal: 1m 39s\tremaining: 1m 44s\n",
      "486:\tlearn: 0.0084204\ttotal: 1m 39s\tremaining: 1m 44s\n",
      "487:\tlearn: 0.0084198\ttotal: 1m 39s\tremaining: 1m 44s\n",
      "488:\tlearn: 0.0084192\ttotal: 1m 39s\tremaining: 1m 44s\n",
      "489:\tlearn: 0.0084183\ttotal: 1m 39s\tremaining: 1m 43s\n",
      "490:\tlearn: 0.0084179\ttotal: 1m 40s\tremaining: 1m 43s\n",
      "491:\tlearn: 0.0084177\ttotal: 1m 40s\tremaining: 1m 43s\n",
      "492:\tlearn: 0.0084177\ttotal: 1m 40s\tremaining: 1m 43s\n",
      "493:\tlearn: 0.0084173\ttotal: 1m 40s\tremaining: 1m 43s\n",
      "494:\tlearn: 0.0084173\ttotal: 1m 40s\tremaining: 1m 43s\n",
      "495:\tlearn: 0.0084169\ttotal: 1m 41s\tremaining: 1m 42s\n",
      "496:\tlearn: 0.0084163\ttotal: 1m 41s\tremaining: 1m 42s\n",
      "497:\tlearn: 0.0084152\ttotal: 1m 41s\tremaining: 1m 42s\n",
      "498:\tlearn: 0.0084147\ttotal: 1m 41s\tremaining: 1m 42s\n",
      "499:\tlearn: 0.0084145\ttotal: 1m 42s\tremaining: 1m 42s\n",
      "500:\tlearn: 0.0084142\ttotal: 1m 42s\tremaining: 1m 42s\n",
      "501:\tlearn: 0.0084140\ttotal: 1m 42s\tremaining: 1m 41s\n",
      "502:\tlearn: 0.0084138\ttotal: 1m 42s\tremaining: 1m 41s\n",
      "503:\tlearn: 0.0084136\ttotal: 1m 43s\tremaining: 1m 41s\n",
      "504:\tlearn: 0.0084133\ttotal: 1m 43s\tremaining: 1m 41s\n",
      "505:\tlearn: 0.0084132\ttotal: 1m 43s\tremaining: 1m 41s\n",
      "506:\tlearn: 0.0084129\ttotal: 1m 43s\tremaining: 1m 40s\n",
      "507:\tlearn: 0.0084123\ttotal: 1m 43s\tremaining: 1m 40s\n",
      "508:\tlearn: 0.0084120\ttotal: 1m 44s\tremaining: 1m 40s\n",
      "509:\tlearn: 0.0084111\ttotal: 1m 44s\tremaining: 1m 40s\n",
      "510:\tlearn: 0.0084108\ttotal: 1m 44s\tremaining: 1m 40s\n",
      "511:\tlearn: 0.0084106\ttotal: 1m 44s\tremaining: 1m 39s\n",
      "512:\tlearn: 0.0084105\ttotal: 1m 44s\tremaining: 1m 39s\n",
      "513:\tlearn: 0.0084104\ttotal: 1m 45s\tremaining: 1m 39s\n",
      "514:\tlearn: 0.0084102\ttotal: 1m 45s\tremaining: 1m 39s\n",
      "515:\tlearn: 0.0084099\ttotal: 1m 45s\tremaining: 1m 39s\n",
      "516:\tlearn: 0.0084099\ttotal: 1m 45s\tremaining: 1m 38s\n",
      "517:\tlearn: 0.0084098\ttotal: 1m 45s\tremaining: 1m 38s\n",
      "518:\tlearn: 0.0084096\ttotal: 1m 46s\tremaining: 1m 38s\n",
      "519:\tlearn: 0.0084091\ttotal: 1m 46s\tremaining: 1m 38s\n",
      "520:\tlearn: 0.0084090\ttotal: 1m 46s\tremaining: 1m 37s\n",
      "521:\tlearn: 0.0084087\ttotal: 1m 46s\tremaining: 1m 37s\n",
      "522:\tlearn: 0.0084084\ttotal: 1m 46s\tremaining: 1m 37s\n",
      "523:\tlearn: 0.0084082\ttotal: 1m 47s\tremaining: 1m 37s\n",
      "524:\tlearn: 0.0084082\ttotal: 1m 47s\tremaining: 1m 37s\n",
      "525:\tlearn: 0.0084079\ttotal: 1m 47s\tremaining: 1m 36s\n",
      "526:\tlearn: 0.0084077\ttotal: 1m 47s\tremaining: 1m 36s\n",
      "527:\tlearn: 0.0084074\ttotal: 1m 47s\tremaining: 1m 36s\n",
      "528:\tlearn: 0.0084071\ttotal: 1m 48s\tremaining: 1m 36s\n",
      "529:\tlearn: 0.0084067\ttotal: 1m 48s\tremaining: 1m 36s\n",
      "530:\tlearn: 0.0084065\ttotal: 1m 48s\tremaining: 1m 35s\n",
      "531:\tlearn: 0.0084065\ttotal: 1m 48s\tremaining: 1m 35s\n",
      "532:\tlearn: 0.0084065\ttotal: 1m 48s\tremaining: 1m 35s\n",
      "533:\tlearn: 0.0084064\ttotal: 1m 49s\tremaining: 1m 35s\n",
      "534:\tlearn: 0.0084064\ttotal: 1m 49s\tremaining: 1m 35s\n",
      "535:\tlearn: 0.0084061\ttotal: 1m 49s\tremaining: 1m 34s\n",
      "536:\tlearn: 0.0084059\ttotal: 1m 49s\tremaining: 1m 34s\n",
      "537:\tlearn: 0.0084055\ttotal: 1m 49s\tremaining: 1m 34s\n",
      "538:\tlearn: 0.0084055\ttotal: 1m 50s\tremaining: 1m 34s\n",
      "539:\tlearn: 0.0084049\ttotal: 1m 50s\tremaining: 1m 33s\n",
      "540:\tlearn: 0.0084046\ttotal: 1m 50s\tremaining: 1m 33s\n",
      "541:\tlearn: 0.0084040\ttotal: 1m 50s\tremaining: 1m 33s\n",
      "542:\tlearn: 0.0084031\ttotal: 1m 50s\tremaining: 1m 33s\n",
      "543:\tlearn: 0.0084029\ttotal: 1m 51s\tremaining: 1m 33s\n",
      "544:\tlearn: 0.0084026\ttotal: 1m 51s\tremaining: 1m 32s\n",
      "545:\tlearn: 0.0084025\ttotal: 1m 51s\tremaining: 1m 32s\n",
      "546:\tlearn: 0.0084023\ttotal: 1m 51s\tremaining: 1m 32s\n",
      "547:\tlearn: 0.0084022\ttotal: 1m 51s\tremaining: 1m 32s\n",
      "548:\tlearn: 0.0084017\ttotal: 1m 52s\tremaining: 1m 32s\n",
      "549:\tlearn: 0.0084017\ttotal: 1m 52s\tremaining: 1m 31s\n",
      "550:\tlearn: 0.0084014\ttotal: 1m 52s\tremaining: 1m 31s\n",
      "551:\tlearn: 0.0084014\ttotal: 1m 52s\tremaining: 1m 31s\n",
      "552:\tlearn: 0.0084002\ttotal: 1m 52s\tremaining: 1m 31s\n",
      "553:\tlearn: 0.0084001\ttotal: 1m 53s\tremaining: 1m 31s\n",
      "554:\tlearn: 0.0083999\ttotal: 1m 53s\tremaining: 1m 30s\n",
      "555:\tlearn: 0.0083995\ttotal: 1m 53s\tremaining: 1m 30s\n",
      "556:\tlearn: 0.0083994\ttotal: 1m 53s\tremaining: 1m 30s\n",
      "557:\tlearn: 0.0083986\ttotal: 1m 53s\tremaining: 1m 30s\n",
      "558:\tlearn: 0.0083984\ttotal: 1m 54s\tremaining: 1m 30s\n",
      "559:\tlearn: 0.0083983\ttotal: 1m 54s\tremaining: 1m 29s\n",
      "560:\tlearn: 0.0083981\ttotal: 1m 54s\tremaining: 1m 29s\n",
      "561:\tlearn: 0.0083981\ttotal: 1m 54s\tremaining: 1m 29s\n",
      "562:\tlearn: 0.0083978\ttotal: 1m 55s\tremaining: 1m 29s\n",
      "563:\tlearn: 0.0083976\ttotal: 1m 55s\tremaining: 1m 29s\n",
      "564:\tlearn: 0.0083976\ttotal: 1m 55s\tremaining: 1m 28s\n",
      "565:\tlearn: 0.0083974\ttotal: 1m 55s\tremaining: 1m 28s\n",
      "566:\tlearn: 0.0083974\ttotal: 1m 55s\tremaining: 1m 28s\n",
      "567:\tlearn: 0.0083972\ttotal: 1m 56s\tremaining: 1m 28s\n",
      "568:\tlearn: 0.0083972\ttotal: 1m 56s\tremaining: 1m 28s\n",
      "569:\tlearn: 0.0083970\ttotal: 1m 56s\tremaining: 1m 27s\n",
      "570:\tlearn: 0.0083968\ttotal: 1m 56s\tremaining: 1m 27s\n",
      "571:\tlearn: 0.0083966\ttotal: 1m 56s\tremaining: 1m 27s\n",
      "572:\tlearn: 0.0083964\ttotal: 1m 57s\tremaining: 1m 27s\n",
      "573:\tlearn: 0.0083963\ttotal: 1m 57s\tremaining: 1m 27s\n",
      "574:\tlearn: 0.0083962\ttotal: 1m 57s\tremaining: 1m 26s\n",
      "575:\tlearn: 0.0083962\ttotal: 1m 57s\tremaining: 1m 26s\n",
      "576:\tlearn: 0.0083949\ttotal: 1m 57s\tremaining: 1m 26s\n",
      "577:\tlearn: 0.0083947\ttotal: 1m 58s\tremaining: 1m 26s\n",
      "578:\tlearn: 0.0083946\ttotal: 1m 58s\tremaining: 1m 26s\n",
      "579:\tlearn: 0.0083945\ttotal: 1m 58s\tremaining: 1m 25s\n",
      "580:\tlearn: 0.0083943\ttotal: 1m 58s\tremaining: 1m 25s\n",
      "581:\tlearn: 0.0083940\ttotal: 1m 58s\tremaining: 1m 25s\n",
      "582:\tlearn: 0.0083933\ttotal: 1m 59s\tremaining: 1m 25s\n",
      "583:\tlearn: 0.0083931\ttotal: 1m 59s\tremaining: 1m 24s\n",
      "584:\tlearn: 0.0083928\ttotal: 1m 59s\tremaining: 1m 24s\n",
      "585:\tlearn: 0.0083928\ttotal: 1m 59s\tremaining: 1m 24s\n",
      "586:\tlearn: 0.0083927\ttotal: 1m 59s\tremaining: 1m 24s\n",
      "587:\tlearn: 0.0083903\ttotal: 2m\tremaining: 1m 24s\n",
      "588:\tlearn: 0.0083903\ttotal: 2m\tremaining: 1m 23s\n",
      "589:\tlearn: 0.0083901\ttotal: 2m\tremaining: 1m 23s\n",
      "590:\tlearn: 0.0083900\ttotal: 2m\tremaining: 1m 23s\n",
      "591:\tlearn: 0.0083893\ttotal: 2m\tremaining: 1m 23s\n",
      "592:\tlearn: 0.0083893\ttotal: 2m 1s\tremaining: 1m 23s\n",
      "593:\tlearn: 0.0083890\ttotal: 2m 1s\tremaining: 1m 22s\n",
      "594:\tlearn: 0.0083882\ttotal: 2m 1s\tremaining: 1m 22s\n",
      "595:\tlearn: 0.0083880\ttotal: 2m 1s\tremaining: 1m 22s\n",
      "596:\tlearn: 0.0083880\ttotal: 2m 1s\tremaining: 1m 22s\n",
      "597:\tlearn: 0.0083880\ttotal: 2m 2s\tremaining: 1m 22s\n",
      "598:\tlearn: 0.0083879\ttotal: 2m 2s\tremaining: 1m 21s\n",
      "599:\tlearn: 0.0083878\ttotal: 2m 2s\tremaining: 1m 21s\n",
      "600:\tlearn: 0.0083878\ttotal: 2m 2s\tremaining: 1m 21s\n",
      "601:\tlearn: 0.0083876\ttotal: 2m 2s\tremaining: 1m 21s\n",
      "602:\tlearn: 0.0083876\ttotal: 2m 3s\tremaining: 1m 21s\n",
      "603:\tlearn: 0.0083875\ttotal: 2m 3s\tremaining: 1m 20s\n",
      "604:\tlearn: 0.0083874\ttotal: 2m 3s\tremaining: 1m 20s\n",
      "605:\tlearn: 0.0083871\ttotal: 2m 3s\tremaining: 1m 20s\n",
      "606:\tlearn: 0.0083869\ttotal: 2m 4s\tremaining: 1m 20s\n",
      "607:\tlearn: 0.0083867\ttotal: 2m 4s\tremaining: 1m 20s\n",
      "608:\tlearn: 0.0083867\ttotal: 2m 4s\tremaining: 1m 19s\n",
      "609:\tlearn: 0.0083859\ttotal: 2m 4s\tremaining: 1m 19s\n",
      "610:\tlearn: 0.0083856\ttotal: 2m 4s\tremaining: 1m 19s\n",
      "611:\tlearn: 0.0083854\ttotal: 2m 4s\tremaining: 1m 19s\n",
      "612:\tlearn: 0.0083849\ttotal: 2m 5s\tremaining: 1m 19s\n",
      "613:\tlearn: 0.0083845\ttotal: 2m 5s\tremaining: 1m 18s\n",
      "614:\tlearn: 0.0083838\ttotal: 2m 5s\tremaining: 1m 18s\n",
      "615:\tlearn: 0.0083835\ttotal: 2m 5s\tremaining: 1m 18s\n",
      "616:\tlearn: 0.0083833\ttotal: 2m 5s\tremaining: 1m 18s\n",
      "617:\tlearn: 0.0083831\ttotal: 2m 6s\tremaining: 1m 17s\n",
      "618:\tlearn: 0.0083831\ttotal: 2m 6s\tremaining: 1m 17s\n",
      "619:\tlearn: 0.0083830\ttotal: 2m 6s\tremaining: 1m 17s\n",
      "620:\tlearn: 0.0083823\ttotal: 2m 6s\tremaining: 1m 17s\n",
      "621:\tlearn: 0.0083816\ttotal: 2m 6s\tremaining: 1m 17s\n",
      "622:\tlearn: 0.0083815\ttotal: 2m 6s\tremaining: 1m 16s\n",
      "623:\tlearn: 0.0083814\ttotal: 2m 7s\tremaining: 1m 16s\n",
      "624:\tlearn: 0.0083806\ttotal: 2m 7s\tremaining: 1m 16s\n",
      "625:\tlearn: 0.0083805\ttotal: 2m 7s\tremaining: 1m 16s\n",
      "626:\tlearn: 0.0083797\ttotal: 2m 7s\tremaining: 1m 15s\n",
      "627:\tlearn: 0.0083796\ttotal: 2m 7s\tremaining: 1m 15s\n",
      "628:\tlearn: 0.0083794\ttotal: 2m 8s\tremaining: 1m 15s\n",
      "629:\tlearn: 0.0083793\ttotal: 2m 8s\tremaining: 1m 15s\n",
      "630:\tlearn: 0.0083793\ttotal: 2m 8s\tremaining: 1m 15s\n",
      "631:\tlearn: 0.0083792\ttotal: 2m 8s\tremaining: 1m 14s\n",
      "632:\tlearn: 0.0083792\ttotal: 2m 8s\tremaining: 1m 14s\n",
      "633:\tlearn: 0.0083792\ttotal: 2m 9s\tremaining: 1m 14s\n",
      "634:\tlearn: 0.0083791\ttotal: 2m 9s\tremaining: 1m 14s\n",
      "635:\tlearn: 0.0083790\ttotal: 2m 9s\tremaining: 1m 14s\n",
      "636:\tlearn: 0.0083789\ttotal: 2m 9s\tremaining: 1m 13s\n",
      "637:\tlearn: 0.0083786\ttotal: 2m 10s\tremaining: 1m 13s\n",
      "638:\tlearn: 0.0083786\ttotal: 2m 10s\tremaining: 1m 13s\n",
      "639:\tlearn: 0.0083784\ttotal: 2m 10s\tremaining: 1m 13s\n",
      "640:\tlearn: 0.0083782\ttotal: 2m 10s\tremaining: 1m 13s\n",
      "641:\tlearn: 0.0083781\ttotal: 2m 10s\tremaining: 1m 13s\n",
      "642:\tlearn: 0.0083779\ttotal: 2m 11s\tremaining: 1m 12s\n",
      "643:\tlearn: 0.0083773\ttotal: 2m 11s\tremaining: 1m 12s\n",
      "644:\tlearn: 0.0083767\ttotal: 2m 11s\tremaining: 1m 12s\n",
      "645:\tlearn: 0.0083767\ttotal: 2m 11s\tremaining: 1m 12s\n",
      "646:\tlearn: 0.0083766\ttotal: 2m 12s\tremaining: 1m 12s\n",
      "647:\tlearn: 0.0083765\ttotal: 2m 12s\tremaining: 1m 11s\n",
      "648:\tlearn: 0.0083763\ttotal: 2m 12s\tremaining: 1m 11s\n",
      "649:\tlearn: 0.0083760\ttotal: 2m 12s\tremaining: 1m 11s\n",
      "650:\tlearn: 0.0083759\ttotal: 2m 12s\tremaining: 1m 11s\n",
      "651:\tlearn: 0.0083758\ttotal: 2m 13s\tremaining: 1m 11s\n",
      "652:\tlearn: 0.0083756\ttotal: 2m 13s\tremaining: 1m 10s\n",
      "653:\tlearn: 0.0083756\ttotal: 2m 13s\tremaining: 1m 10s\n",
      "654:\tlearn: 0.0083755\ttotal: 2m 13s\tremaining: 1m 10s\n",
      "655:\tlearn: 0.0083755\ttotal: 2m 13s\tremaining: 1m 10s\n",
      "656:\tlearn: 0.0083755\ttotal: 2m 14s\tremaining: 1m 10s\n",
      "657:\tlearn: 0.0083749\ttotal: 2m 14s\tremaining: 1m 9s\n",
      "658:\tlearn: 0.0083748\ttotal: 2m 14s\tremaining: 1m 9s\n",
      "659:\tlearn: 0.0083747\ttotal: 2m 14s\tremaining: 1m 9s\n",
      "660:\tlearn: 0.0083743\ttotal: 2m 15s\tremaining: 1m 9s\n",
      "661:\tlearn: 0.0083743\ttotal: 2m 15s\tremaining: 1m 9s\n",
      "662:\tlearn: 0.0083741\ttotal: 2m 15s\tremaining: 1m 8s\n",
      "663:\tlearn: 0.0083739\ttotal: 2m 15s\tremaining: 1m 8s\n",
      "664:\tlearn: 0.0083737\ttotal: 2m 15s\tremaining: 1m 8s\n",
      "665:\tlearn: 0.0083735\ttotal: 2m 16s\tremaining: 1m 8s\n",
      "666:\tlearn: 0.0083735\ttotal: 2m 16s\tremaining: 1m 8s\n",
      "667:\tlearn: 0.0083729\ttotal: 2m 16s\tremaining: 1m 7s\n",
      "668:\tlearn: 0.0083728\ttotal: 2m 16s\tremaining: 1m 7s\n",
      "669:\tlearn: 0.0083727\ttotal: 2m 16s\tremaining: 1m 7s\n",
      "670:\tlearn: 0.0083710\ttotal: 2m 16s\tremaining: 1m 7s\n",
      "671:\tlearn: 0.0083705\ttotal: 2m 17s\tremaining: 1m 6s\n",
      "672:\tlearn: 0.0083704\ttotal: 2m 17s\tremaining: 1m 6s\n",
      "673:\tlearn: 0.0083702\ttotal: 2m 17s\tremaining: 1m 6s\n",
      "674:\tlearn: 0.0083701\ttotal: 2m 17s\tremaining: 1m 6s\n",
      "675:\tlearn: 0.0083699\ttotal: 2m 17s\tremaining: 1m 6s\n",
      "676:\tlearn: 0.0083698\ttotal: 2m 18s\tremaining: 1m 5s\n",
      "677:\tlearn: 0.0083698\ttotal: 2m 18s\tremaining: 1m 5s\n",
      "678:\tlearn: 0.0083693\ttotal: 2m 18s\tremaining: 1m 5s\n",
      "679:\tlearn: 0.0083686\ttotal: 2m 18s\tremaining: 1m 5s\n",
      "680:\tlearn: 0.0083683\ttotal: 2m 18s\tremaining: 1m 5s\n",
      "681:\tlearn: 0.0083681\ttotal: 2m 19s\tremaining: 1m 4s\n",
      "682:\tlearn: 0.0083680\ttotal: 2m 19s\tremaining: 1m 4s\n",
      "683:\tlearn: 0.0083679\ttotal: 2m 19s\tremaining: 1m 4s\n",
      "684:\tlearn: 0.0083678\ttotal: 2m 19s\tremaining: 1m 4s\n",
      "685:\tlearn: 0.0083677\ttotal: 2m 19s\tremaining: 1m 4s\n",
      "686:\tlearn: 0.0083676\ttotal: 2m 20s\tremaining: 1m 3s\n",
      "687:\tlearn: 0.0083676\ttotal: 2m 20s\tremaining: 1m 3s\n",
      "688:\tlearn: 0.0083675\ttotal: 2m 20s\tremaining: 1m 3s\n",
      "689:\tlearn: 0.0083674\ttotal: 2m 20s\tremaining: 1m 3s\n",
      "690:\tlearn: 0.0083673\ttotal: 2m 20s\tremaining: 1m 2s\n",
      "691:\tlearn: 0.0083667\ttotal: 2m 21s\tremaining: 1m 2s\n",
      "692:\tlearn: 0.0083667\ttotal: 2m 21s\tremaining: 1m 2s\n",
      "693:\tlearn: 0.0083667\ttotal: 2m 21s\tremaining: 1m 2s\n",
      "694:\tlearn: 0.0083665\ttotal: 2m 21s\tremaining: 1m 2s\n",
      "695:\tlearn: 0.0083665\ttotal: 2m 21s\tremaining: 1m 1s\n",
      "696:\tlearn: 0.0083664\ttotal: 2m 22s\tremaining: 1m 1s\n",
      "697:\tlearn: 0.0083663\ttotal: 2m 22s\tremaining: 1m 1s\n",
      "698:\tlearn: 0.0083663\ttotal: 2m 22s\tremaining: 1m 1s\n",
      "699:\tlearn: 0.0083662\ttotal: 2m 22s\tremaining: 1m 1s\n",
      "700:\tlearn: 0.0083662\ttotal: 2m 22s\tremaining: 1m\n",
      "701:\tlearn: 0.0083662\ttotal: 2m 22s\tremaining: 1m\n",
      "702:\tlearn: 0.0083660\ttotal: 2m 23s\tremaining: 1m\n",
      "703:\tlearn: 0.0083660\ttotal: 2m 23s\tremaining: 1m\n",
      "704:\tlearn: 0.0083660\ttotal: 2m 23s\tremaining: 1m\n",
      "705:\tlearn: 0.0083660\ttotal: 2m 23s\tremaining: 59.9s\n",
      "706:\tlearn: 0.0083656\ttotal: 2m 24s\tremaining: 59.7s\n",
      "707:\tlearn: 0.0083655\ttotal: 2m 24s\tremaining: 59.5s\n",
      "708:\tlearn: 0.0083654\ttotal: 2m 24s\tremaining: 59.3s\n",
      "709:\tlearn: 0.0083652\ttotal: 2m 24s\tremaining: 59.1s\n",
      "710:\tlearn: 0.0083648\ttotal: 2m 24s\tremaining: 58.9s\n",
      "711:\tlearn: 0.0083648\ttotal: 2m 25s\tremaining: 58.7s\n",
      "712:\tlearn: 0.0083647\ttotal: 2m 25s\tremaining: 58.5s\n",
      "713:\tlearn: 0.0083647\ttotal: 2m 25s\tremaining: 58.3s\n",
      "714:\tlearn: 0.0083647\ttotal: 2m 25s\tremaining: 58.1s\n",
      "715:\tlearn: 0.0083646\ttotal: 2m 25s\tremaining: 57.9s\n",
      "716:\tlearn: 0.0083645\ttotal: 2m 26s\tremaining: 57.7s\n",
      "717:\tlearn: 0.0083645\ttotal: 2m 26s\tremaining: 57.5s\n",
      "718:\tlearn: 0.0083643\ttotal: 2m 26s\tremaining: 57.3s\n",
      "719:\tlearn: 0.0083642\ttotal: 2m 26s\tremaining: 57.1s\n",
      "720:\tlearn: 0.0083639\ttotal: 2m 27s\tremaining: 56.9s\n",
      "721:\tlearn: 0.0083638\ttotal: 2m 27s\tremaining: 56.7s\n",
      "722:\tlearn: 0.0083638\ttotal: 2m 27s\tremaining: 56.5s\n",
      "723:\tlearn: 0.0083638\ttotal: 2m 27s\tremaining: 56.3s\n",
      "724:\tlearn: 0.0083636\ttotal: 2m 27s\tremaining: 56.1s\n",
      "725:\tlearn: 0.0083635\ttotal: 2m 27s\tremaining: 55.8s\n",
      "726:\tlearn: 0.0083635\ttotal: 2m 28s\tremaining: 55.6s\n",
      "727:\tlearn: 0.0083634\ttotal: 2m 28s\tremaining: 55.4s\n",
      "728:\tlearn: 0.0083634\ttotal: 2m 28s\tremaining: 55.2s\n",
      "729:\tlearn: 0.0083630\ttotal: 2m 28s\tremaining: 55s\n",
      "730:\tlearn: 0.0083629\ttotal: 2m 28s\tremaining: 54.8s\n",
      "731:\tlearn: 0.0083628\ttotal: 2m 29s\tremaining: 54.6s\n",
      "732:\tlearn: 0.0083628\ttotal: 2m 29s\tremaining: 54.4s\n",
      "733:\tlearn: 0.0083628\ttotal: 2m 29s\tremaining: 54.2s\n",
      "734:\tlearn: 0.0083626\ttotal: 2m 29s\tremaining: 54s\n",
      "735:\tlearn: 0.0083625\ttotal: 2m 29s\tremaining: 53.7s\n",
      "736:\tlearn: 0.0083625\ttotal: 2m 30s\tremaining: 53.5s\n",
      "737:\tlearn: 0.0083624\ttotal: 2m 30s\tremaining: 53.3s\n",
      "738:\tlearn: 0.0083623\ttotal: 2m 30s\tremaining: 53.1s\n",
      "739:\tlearn: 0.0083623\ttotal: 2m 30s\tremaining: 52.9s\n",
      "740:\tlearn: 0.0083622\ttotal: 2m 30s\tremaining: 52.7s\n",
      "741:\tlearn: 0.0083622\ttotal: 2m 30s\tremaining: 52.5s\n",
      "742:\tlearn: 0.0083617\ttotal: 2m 31s\tremaining: 52.3s\n",
      "743:\tlearn: 0.0083616\ttotal: 2m 31s\tremaining: 52.1s\n",
      "744:\tlearn: 0.0083615\ttotal: 2m 31s\tremaining: 51.9s\n",
      "745:\tlearn: 0.0083615\ttotal: 2m 31s\tremaining: 51.7s\n",
      "746:\tlearn: 0.0083613\ttotal: 2m 31s\tremaining: 51.5s\n",
      "747:\tlearn: 0.0083613\ttotal: 2m 32s\tremaining: 51.2s\n",
      "748:\tlearn: 0.0083612\ttotal: 2m 32s\tremaining: 51s\n",
      "749:\tlearn: 0.0083612\ttotal: 2m 32s\tremaining: 50.8s\n",
      "750:\tlearn: 0.0083611\ttotal: 2m 32s\tremaining: 50.6s\n",
      "751:\tlearn: 0.0083611\ttotal: 2m 32s\tremaining: 50.4s\n",
      "752:\tlearn: 0.0083610\ttotal: 2m 33s\tremaining: 50.2s\n",
      "753:\tlearn: 0.0083610\ttotal: 2m 33s\tremaining: 50s\n",
      "754:\tlearn: 0.0083609\ttotal: 2m 33s\tremaining: 49.8s\n",
      "755:\tlearn: 0.0083608\ttotal: 2m 33s\tremaining: 49.6s\n",
      "756:\tlearn: 0.0083608\ttotal: 2m 33s\tremaining: 49.4s\n",
      "757:\tlearn: 0.0083606\ttotal: 2m 34s\tremaining: 49.2s\n",
      "758:\tlearn: 0.0083606\ttotal: 2m 34s\tremaining: 49s\n",
      "759:\tlearn: 0.0083606\ttotal: 2m 34s\tremaining: 48.8s\n",
      "760:\tlearn: 0.0083606\ttotal: 2m 34s\tremaining: 48.6s\n",
      "761:\tlearn: 0.0083605\ttotal: 2m 34s\tremaining: 48.3s\n",
      "762:\tlearn: 0.0083600\ttotal: 2m 34s\tremaining: 48.1s\n",
      "763:\tlearn: 0.0083600\ttotal: 2m 35s\tremaining: 47.9s\n",
      "764:\tlearn: 0.0083600\ttotal: 2m 35s\tremaining: 47.7s\n",
      "765:\tlearn: 0.0083600\ttotal: 2m 35s\tremaining: 47.5s\n",
      "766:\tlearn: 0.0083599\ttotal: 2m 35s\tremaining: 47.3s\n",
      "767:\tlearn: 0.0083597\ttotal: 2m 35s\tremaining: 47.1s\n",
      "768:\tlearn: 0.0083596\ttotal: 2m 36s\tremaining: 46.9s\n",
      "769:\tlearn: 0.0083595\ttotal: 2m 36s\tremaining: 46.7s\n",
      "770:\tlearn: 0.0083595\ttotal: 2m 36s\tremaining: 46.5s\n",
      "771:\tlearn: 0.0083594\ttotal: 2m 36s\tremaining: 46.3s\n",
      "772:\tlearn: 0.0083593\ttotal: 2m 36s\tremaining: 46.1s\n",
      "773:\tlearn: 0.0083591\ttotal: 2m 37s\tremaining: 45.9s\n",
      "774:\tlearn: 0.0083590\ttotal: 2m 37s\tremaining: 45.7s\n",
      "775:\tlearn: 0.0083584\ttotal: 2m 37s\tremaining: 45.5s\n",
      "776:\tlearn: 0.0083584\ttotal: 2m 37s\tremaining: 45.3s\n",
      "777:\tlearn: 0.0083582\ttotal: 2m 38s\tremaining: 45.1s\n",
      "778:\tlearn: 0.0083582\ttotal: 2m 38s\tremaining: 44.9s\n",
      "779:\tlearn: 0.0083581\ttotal: 2m 38s\tremaining: 44.7s\n",
      "780:\tlearn: 0.0083581\ttotal: 2m 38s\tremaining: 44.5s\n",
      "781:\tlearn: 0.0083581\ttotal: 2m 38s\tremaining: 44.3s\n",
      "782:\tlearn: 0.0083580\ttotal: 2m 39s\tremaining: 44.1s\n",
      "783:\tlearn: 0.0083576\ttotal: 2m 39s\tremaining: 43.9s\n",
      "784:\tlearn: 0.0083576\ttotal: 2m 39s\tremaining: 43.7s\n",
      "785:\tlearn: 0.0083575\ttotal: 2m 39s\tremaining: 43.5s\n",
      "786:\tlearn: 0.0083575\ttotal: 2m 39s\tremaining: 43.3s\n",
      "787:\tlearn: 0.0083574\ttotal: 2m 40s\tremaining: 43.1s\n",
      "788:\tlearn: 0.0083573\ttotal: 2m 40s\tremaining: 42.9s\n",
      "789:\tlearn: 0.0083573\ttotal: 2m 40s\tremaining: 42.7s\n",
      "790:\tlearn: 0.0083571\ttotal: 2m 40s\tremaining: 42.5s\n",
      "791:\tlearn: 0.0083566\ttotal: 2m 40s\tremaining: 42.3s\n",
      "792:\tlearn: 0.0083565\ttotal: 2m 41s\tremaining: 42.1s\n",
      "793:\tlearn: 0.0083564\ttotal: 2m 41s\tremaining: 41.9s\n",
      "794:\tlearn: 0.0083564\ttotal: 2m 41s\tremaining: 41.7s\n",
      "795:\tlearn: 0.0083559\ttotal: 2m 41s\tremaining: 41.5s\n",
      "796:\tlearn: 0.0083557\ttotal: 2m 42s\tremaining: 41.3s\n",
      "797:\tlearn: 0.0083556\ttotal: 2m 42s\tremaining: 41.1s\n",
      "798:\tlearn: 0.0083555\ttotal: 2m 42s\tremaining: 40.9s\n",
      "799:\tlearn: 0.0083555\ttotal: 2m 42s\tremaining: 40.7s\n",
      "800:\tlearn: 0.0083553\ttotal: 2m 42s\tremaining: 40.5s\n",
      "801:\tlearn: 0.0083553\ttotal: 2m 43s\tremaining: 40.3s\n",
      "802:\tlearn: 0.0083551\ttotal: 2m 43s\tremaining: 40.1s\n",
      "803:\tlearn: 0.0083551\ttotal: 2m 43s\tremaining: 39.9s\n",
      "804:\tlearn: 0.0083550\ttotal: 2m 43s\tremaining: 39.7s\n",
      "805:\tlearn: 0.0083550\ttotal: 2m 43s\tremaining: 39.5s\n",
      "806:\tlearn: 0.0083547\ttotal: 2m 44s\tremaining: 39.3s\n",
      "807:\tlearn: 0.0083546\ttotal: 2m 44s\tremaining: 39.1s\n",
      "808:\tlearn: 0.0083542\ttotal: 2m 44s\tremaining: 38.9s\n",
      "809:\tlearn: 0.0083542\ttotal: 2m 44s\tremaining: 38.6s\n",
      "810:\tlearn: 0.0083541\ttotal: 2m 44s\tremaining: 38.4s\n",
      "811:\tlearn: 0.0083541\ttotal: 2m 45s\tremaining: 38.2s\n",
      "812:\tlearn: 0.0083538\ttotal: 2m 45s\tremaining: 38s\n",
      "813:\tlearn: 0.0083537\ttotal: 2m 45s\tremaining: 37.8s\n",
      "814:\tlearn: 0.0083534\ttotal: 2m 45s\tremaining: 37.6s\n",
      "815:\tlearn: 0.0083534\ttotal: 2m 46s\tremaining: 37.4s\n",
      "816:\tlearn: 0.0083534\ttotal: 2m 46s\tremaining: 37.2s\n",
      "817:\tlearn: 0.0083533\ttotal: 2m 46s\tremaining: 37s\n",
      "818:\tlearn: 0.0083533\ttotal: 2m 46s\tremaining: 36.8s\n",
      "819:\tlearn: 0.0083532\ttotal: 2m 46s\tremaining: 36.6s\n",
      "820:\tlearn: 0.0083531\ttotal: 2m 47s\tremaining: 36.4s\n",
      "821:\tlearn: 0.0083531\ttotal: 2m 47s\tremaining: 36.2s\n",
      "822:\tlearn: 0.0083530\ttotal: 2m 47s\tremaining: 36s\n",
      "823:\tlearn: 0.0083526\ttotal: 2m 47s\tremaining: 35.8s\n",
      "824:\tlearn: 0.0083526\ttotal: 2m 47s\tremaining: 35.6s\n",
      "825:\tlearn: 0.0083525\ttotal: 2m 48s\tremaining: 35.4s\n",
      "826:\tlearn: 0.0083525\ttotal: 2m 48s\tremaining: 35.2s\n",
      "827:\tlearn: 0.0083524\ttotal: 2m 48s\tremaining: 35s\n",
      "828:\tlearn: 0.0083523\ttotal: 2m 48s\tremaining: 34.8s\n",
      "829:\tlearn: 0.0083522\ttotal: 2m 48s\tremaining: 34.6s\n",
      "830:\tlearn: 0.0083520\ttotal: 2m 49s\tremaining: 34.4s\n",
      "831:\tlearn: 0.0083517\ttotal: 2m 49s\tremaining: 34.2s\n",
      "832:\tlearn: 0.0083516\ttotal: 2m 49s\tremaining: 34s\n",
      "833:\tlearn: 0.0083516\ttotal: 2m 49s\tremaining: 33.8s\n",
      "834:\tlearn: 0.0083514\ttotal: 2m 49s\tremaining: 33.6s\n",
      "835:\tlearn: 0.0083514\ttotal: 2m 50s\tremaining: 33.4s\n",
      "836:\tlearn: 0.0083514\ttotal: 2m 50s\tremaining: 33.1s\n",
      "837:\tlearn: 0.0083514\ttotal: 2m 50s\tremaining: 32.9s\n",
      "838:\tlearn: 0.0083514\ttotal: 2m 50s\tremaining: 32.7s\n",
      "839:\tlearn: 0.0083514\ttotal: 2m 50s\tremaining: 32.5s\n",
      "840:\tlearn: 0.0083512\ttotal: 2m 50s\tremaining: 32.3s\n",
      "841:\tlearn: 0.0083512\ttotal: 2m 51s\tremaining: 32.1s\n",
      "842:\tlearn: 0.0083511\ttotal: 2m 51s\tremaining: 31.9s\n",
      "843:\tlearn: 0.0083511\ttotal: 2m 51s\tremaining: 31.7s\n",
      "844:\tlearn: 0.0083510\ttotal: 2m 51s\tremaining: 31.5s\n",
      "845:\tlearn: 0.0083509\ttotal: 2m 52s\tremaining: 31.3s\n",
      "846:\tlearn: 0.0083508\ttotal: 2m 52s\tremaining: 31.1s\n",
      "847:\tlearn: 0.0083508\ttotal: 2m 52s\tremaining: 30.9s\n",
      "848:\tlearn: 0.0083507\ttotal: 2m 52s\tremaining: 30.7s\n",
      "849:\tlearn: 0.0083505\ttotal: 2m 52s\tremaining: 30.5s\n",
      "850:\tlearn: 0.0083505\ttotal: 2m 52s\tremaining: 30.3s\n",
      "851:\tlearn: 0.0083501\ttotal: 2m 53s\tremaining: 30.1s\n",
      "852:\tlearn: 0.0083500\ttotal: 2m 53s\tremaining: 29.9s\n",
      "853:\tlearn: 0.0083497\ttotal: 2m 53s\tremaining: 29.7s\n",
      "854:\tlearn: 0.0083494\ttotal: 2m 53s\tremaining: 29.5s\n",
      "855:\tlearn: 0.0083494\ttotal: 2m 54s\tremaining: 29.3s\n",
      "856:\tlearn: 0.0083493\ttotal: 2m 54s\tremaining: 29.1s\n",
      "857:\tlearn: 0.0083493\ttotal: 2m 54s\tremaining: 28.9s\n",
      "858:\tlearn: 0.0083493\ttotal: 2m 54s\tremaining: 28.7s\n",
      "859:\tlearn: 0.0083491\ttotal: 2m 54s\tremaining: 28.5s\n",
      "860:\tlearn: 0.0083490\ttotal: 2m 55s\tremaining: 28.3s\n",
      "861:\tlearn: 0.0083489\ttotal: 2m 55s\tremaining: 28.1s\n",
      "862:\tlearn: 0.0083489\ttotal: 2m 55s\tremaining: 27.9s\n",
      "863:\tlearn: 0.0083489\ttotal: 2m 55s\tremaining: 27.7s\n",
      "864:\tlearn: 0.0083489\ttotal: 2m 55s\tremaining: 27.5s\n",
      "865:\tlearn: 0.0083489\ttotal: 2m 56s\tremaining: 27.3s\n",
      "866:\tlearn: 0.0083488\ttotal: 2m 56s\tremaining: 27s\n",
      "867:\tlearn: 0.0083488\ttotal: 2m 56s\tremaining: 26.8s\n",
      "868:\tlearn: 0.0083486\ttotal: 2m 56s\tremaining: 26.6s\n",
      "869:\tlearn: 0.0083486\ttotal: 2m 56s\tremaining: 26.4s\n",
      "870:\tlearn: 0.0083486\ttotal: 2m 57s\tremaining: 26.2s\n",
      "871:\tlearn: 0.0083486\ttotal: 2m 57s\tremaining: 26s\n",
      "872:\tlearn: 0.0083486\ttotal: 2m 57s\tremaining: 25.8s\n",
      "873:\tlearn: 0.0083486\ttotal: 2m 57s\tremaining: 25.6s\n",
      "874:\tlearn: 0.0083485\ttotal: 2m 57s\tremaining: 25.4s\n",
      "875:\tlearn: 0.0083485\ttotal: 2m 58s\tremaining: 25.2s\n",
      "876:\tlearn: 0.0083484\ttotal: 2m 58s\tremaining: 25s\n",
      "877:\tlearn: 0.0083484\ttotal: 2m 58s\tremaining: 24.8s\n",
      "878:\tlearn: 0.0083484\ttotal: 2m 58s\tremaining: 24.6s\n",
      "879:\tlearn: 0.0083483\ttotal: 2m 58s\tremaining: 24.4s\n",
      "880:\tlearn: 0.0083482\ttotal: 2m 59s\tremaining: 24.2s\n",
      "881:\tlearn: 0.0083482\ttotal: 2m 59s\tremaining: 24s\n",
      "882:\tlearn: 0.0083482\ttotal: 2m 59s\tremaining: 23.8s\n",
      "883:\tlearn: 0.0083482\ttotal: 2m 59s\tremaining: 23.6s\n",
      "884:\tlearn: 0.0083481\ttotal: 2m 59s\tremaining: 23.4s\n",
      "885:\tlearn: 0.0083481\ttotal: 3m\tremaining: 23.2s\n",
      "886:\tlearn: 0.0083481\ttotal: 3m\tremaining: 23s\n",
      "887:\tlearn: 0.0083481\ttotal: 3m\tremaining: 22.8s\n",
      "888:\tlearn: 0.0083480\ttotal: 3m\tremaining: 22.6s\n",
      "889:\tlearn: 0.0083480\ttotal: 3m\tremaining: 22.3s\n",
      "890:\tlearn: 0.0083478\ttotal: 3m 1s\tremaining: 22.1s\n",
      "891:\tlearn: 0.0083477\ttotal: 3m 1s\tremaining: 21.9s\n",
      "892:\tlearn: 0.0083477\ttotal: 3m 1s\tremaining: 21.7s\n",
      "893:\tlearn: 0.0083477\ttotal: 3m 1s\tremaining: 21.5s\n",
      "894:\tlearn: 0.0083476\ttotal: 3m 1s\tremaining: 21.3s\n",
      "895:\tlearn: 0.0083476\ttotal: 3m 1s\tremaining: 21.1s\n",
      "896:\tlearn: 0.0083476\ttotal: 3m 2s\tremaining: 20.9s\n",
      "897:\tlearn: 0.0083476\ttotal: 3m 2s\tremaining: 20.7s\n",
      "898:\tlearn: 0.0083472\ttotal: 3m 2s\tremaining: 20.5s\n",
      "899:\tlearn: 0.0083470\ttotal: 3m 2s\tremaining: 20.3s\n",
      "900:\tlearn: 0.0083467\ttotal: 3m 2s\tremaining: 20.1s\n",
      "901:\tlearn: 0.0083467\ttotal: 3m 3s\tremaining: 19.9s\n",
      "902:\tlearn: 0.0083467\ttotal: 3m 3s\tremaining: 19.7s\n",
      "903:\tlearn: 0.0083467\ttotal: 3m 3s\tremaining: 19.5s\n",
      "904:\tlearn: 0.0083467\ttotal: 3m 3s\tremaining: 19.3s\n",
      "905:\tlearn: 0.0083464\ttotal: 3m 3s\tremaining: 19.1s\n",
      "906:\tlearn: 0.0083464\ttotal: 3m 4s\tremaining: 18.9s\n",
      "907:\tlearn: 0.0083464\ttotal: 3m 4s\tremaining: 18.7s\n",
      "908:\tlearn: 0.0083464\ttotal: 3m 4s\tremaining: 18.5s\n",
      "909:\tlearn: 0.0083464\ttotal: 3m 4s\tremaining: 18.3s\n",
      "910:\tlearn: 0.0083462\ttotal: 3m 4s\tremaining: 18.1s\n",
      "911:\tlearn: 0.0083462\ttotal: 3m 4s\tremaining: 17.8s\n",
      "912:\tlearn: 0.0083461\ttotal: 3m 5s\tremaining: 17.6s\n",
      "913:\tlearn: 0.0083461\ttotal: 3m 5s\tremaining: 17.4s\n",
      "914:\tlearn: 0.0083460\ttotal: 3m 5s\tremaining: 17.2s\n",
      "915:\tlearn: 0.0083460\ttotal: 3m 5s\tremaining: 17s\n",
      "916:\tlearn: 0.0083460\ttotal: 3m 5s\tremaining: 16.8s\n",
      "917:\tlearn: 0.0083458\ttotal: 3m 6s\tremaining: 16.6s\n",
      "918:\tlearn: 0.0083458\ttotal: 3m 6s\tremaining: 16.4s\n",
      "919:\tlearn: 0.0083457\ttotal: 3m 6s\tremaining: 16.2s\n",
      "920:\tlearn: 0.0083456\ttotal: 3m 6s\tremaining: 16s\n",
      "921:\tlearn: 0.0083455\ttotal: 3m 6s\tremaining: 15.8s\n",
      "922:\tlearn: 0.0083454\ttotal: 3m 7s\tremaining: 15.6s\n",
      "923:\tlearn: 0.0083453\ttotal: 3m 7s\tremaining: 15.4s\n",
      "924:\tlearn: 0.0083452\ttotal: 3m 7s\tremaining: 15.2s\n",
      "925:\tlearn: 0.0083452\ttotal: 3m 7s\tremaining: 15s\n",
      "926:\tlearn: 0.0083452\ttotal: 3m 7s\tremaining: 14.8s\n",
      "927:\tlearn: 0.0083451\ttotal: 3m 7s\tremaining: 14.6s\n",
      "928:\tlearn: 0.0083450\ttotal: 3m 8s\tremaining: 14.4s\n",
      "929:\tlearn: 0.0083450\ttotal: 3m 8s\tremaining: 14.2s\n",
      "930:\tlearn: 0.0083450\ttotal: 3m 8s\tremaining: 14s\n",
      "931:\tlearn: 0.0083449\ttotal: 3m 8s\tremaining: 13.8s\n",
      "932:\tlearn: 0.0083449\ttotal: 3m 8s\tremaining: 13.6s\n",
      "933:\tlearn: 0.0083448\ttotal: 3m 9s\tremaining: 13.4s\n",
      "934:\tlearn: 0.0083447\ttotal: 3m 9s\tremaining: 13.2s\n",
      "935:\tlearn: 0.0083447\ttotal: 3m 9s\tremaining: 13s\n",
      "936:\tlearn: 0.0083446\ttotal: 3m 9s\tremaining: 12.8s\n",
      "937:\tlearn: 0.0083446\ttotal: 3m 9s\tremaining: 12.6s\n",
      "938:\tlearn: 0.0083445\ttotal: 3m 10s\tremaining: 12.3s\n",
      "939:\tlearn: 0.0083445\ttotal: 3m 10s\tremaining: 12.1s\n",
      "940:\tlearn: 0.0083445\ttotal: 3m 10s\tremaining: 11.9s\n",
      "941:\tlearn: 0.0083445\ttotal: 3m 10s\tremaining: 11.7s\n",
      "942:\tlearn: 0.0083445\ttotal: 3m 10s\tremaining: 11.5s\n",
      "943:\tlearn: 0.0083444\ttotal: 3m 11s\tremaining: 11.3s\n",
      "944:\tlearn: 0.0083444\ttotal: 3m 11s\tremaining: 11.1s\n",
      "945:\tlearn: 0.0083442\ttotal: 3m 11s\tremaining: 10.9s\n",
      "946:\tlearn: 0.0083442\ttotal: 3m 11s\tremaining: 10.7s\n",
      "947:\tlearn: 0.0083442\ttotal: 3m 11s\tremaining: 10.5s\n",
      "948:\tlearn: 0.0083441\ttotal: 3m 12s\tremaining: 10.3s\n",
      "949:\tlearn: 0.0083440\ttotal: 3m 12s\tremaining: 10.1s\n",
      "950:\tlearn: 0.0083440\ttotal: 3m 12s\tremaining: 9.91s\n",
      "951:\tlearn: 0.0083440\ttotal: 3m 12s\tremaining: 9.71s\n",
      "952:\tlearn: 0.0083440\ttotal: 3m 12s\tremaining: 9.51s\n",
      "953:\tlearn: 0.0083440\ttotal: 3m 12s\tremaining: 9.3s\n",
      "954:\tlearn: 0.0083439\ttotal: 3m 13s\tremaining: 9.1s\n",
      "955:\tlearn: 0.0083439\ttotal: 3m 13s\tremaining: 8.9s\n",
      "956:\tlearn: 0.0083439\ttotal: 3m 13s\tremaining: 8.7s\n",
      "957:\tlearn: 0.0083438\ttotal: 3m 13s\tremaining: 8.49s\n",
      "958:\tlearn: 0.0083438\ttotal: 3m 13s\tremaining: 8.29s\n",
      "959:\tlearn: 0.0083438\ttotal: 3m 14s\tremaining: 8.09s\n",
      "960:\tlearn: 0.0083437\ttotal: 3m 14s\tremaining: 7.89s\n",
      "961:\tlearn: 0.0083437\ttotal: 3m 14s\tremaining: 7.68s\n",
      "962:\tlearn: 0.0083437\ttotal: 3m 14s\tremaining: 7.48s\n",
      "963:\tlearn: 0.0083437\ttotal: 3m 14s\tremaining: 7.28s\n",
      "964:\tlearn: 0.0083437\ttotal: 3m 15s\tremaining: 7.08s\n",
      "965:\tlearn: 0.0083435\ttotal: 3m 15s\tremaining: 6.88s\n",
      "966:\tlearn: 0.0083435\ttotal: 3m 15s\tremaining: 6.67s\n",
      "967:\tlearn: 0.0083435\ttotal: 3m 15s\tremaining: 6.47s\n",
      "968:\tlearn: 0.0083434\ttotal: 3m 15s\tremaining: 6.27s\n",
      "969:\tlearn: 0.0083431\ttotal: 3m 16s\tremaining: 6.07s\n",
      "970:\tlearn: 0.0083430\ttotal: 3m 16s\tremaining: 5.86s\n",
      "971:\tlearn: 0.0083430\ttotal: 3m 16s\tremaining: 5.66s\n",
      "972:\tlearn: 0.0083430\ttotal: 3m 16s\tremaining: 5.46s\n",
      "973:\tlearn: 0.0083430\ttotal: 3m 16s\tremaining: 5.26s\n",
      "974:\tlearn: 0.0083429\ttotal: 3m 17s\tremaining: 5.05s\n",
      "975:\tlearn: 0.0083428\ttotal: 3m 17s\tremaining: 4.85s\n",
      "976:\tlearn: 0.0083428\ttotal: 3m 17s\tremaining: 4.65s\n",
      "977:\tlearn: 0.0083426\ttotal: 3m 17s\tremaining: 4.45s\n",
      "978:\tlearn: 0.0083426\ttotal: 3m 18s\tremaining: 4.25s\n",
      "979:\tlearn: 0.0083425\ttotal: 3m 18s\tremaining: 4.04s\n",
      "980:\tlearn: 0.0083424\ttotal: 3m 18s\tremaining: 3.84s\n",
      "981:\tlearn: 0.0083423\ttotal: 3m 18s\tremaining: 3.64s\n",
      "982:\tlearn: 0.0083421\ttotal: 3m 18s\tremaining: 3.44s\n",
      "983:\tlearn: 0.0083421\ttotal: 3m 19s\tremaining: 3.24s\n",
      "984:\tlearn: 0.0083420\ttotal: 3m 19s\tremaining: 3.03s\n",
      "985:\tlearn: 0.0083417\ttotal: 3m 19s\tremaining: 2.83s\n",
      "986:\tlearn: 0.0083417\ttotal: 3m 19s\tremaining: 2.63s\n",
      "987:\tlearn: 0.0083414\ttotal: 3m 19s\tremaining: 2.43s\n",
      "988:\tlearn: 0.0083414\ttotal: 3m 20s\tremaining: 2.23s\n",
      "989:\tlearn: 0.0083413\ttotal: 3m 20s\tremaining: 2.02s\n",
      "990:\tlearn: 0.0083413\ttotal: 3m 20s\tremaining: 1.82s\n",
      "991:\tlearn: 0.0083413\ttotal: 3m 20s\tremaining: 1.62s\n",
      "992:\tlearn: 0.0083413\ttotal: 3m 20s\tremaining: 1.42s\n",
      "993:\tlearn: 0.0083412\ttotal: 3m 21s\tremaining: 1.21s\n",
      "994:\tlearn: 0.0083412\ttotal: 3m 21s\tremaining: 1.01s\n",
      "995:\tlearn: 0.0083412\ttotal: 3m 21s\tremaining: 809ms\n",
      "996:\tlearn: 0.0083411\ttotal: 3m 21s\tremaining: 607ms\n",
      "997:\tlearn: 0.0083409\ttotal: 3m 21s\tremaining: 405ms\n",
      "998:\tlearn: 0.0083409\ttotal: 3m 22s\tremaining: 202ms\n",
      "999:\tlearn: 0.0083408\ttotal: 3m 22s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "cat_model = CatBoostClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9943566749081563"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cat_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.66      0.79      1178\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "         2.0       1.00      1.00      1.00       169\n",
      "         3.0       1.00      1.00      1.00       155\n",
      "         4.0       1.00      1.00      1.00       305\n",
      "         5.0       1.00      1.00      1.00       120\n",
      "         6.0       1.00      1.00      1.00        28\n",
      "         7.0       0.99      1.00      1.00     69571\n",
      "\n",
      "    accuracy                           0.99     71589\n",
      "   macro avg       1.00      0.96      0.97     71589\n",
      "weighted avg       0.99      0.99      0.99     71589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, cat_model.predict(X_test))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model = GradientBoostingClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9942588945229016"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gbm_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, gbm_model.predict(X_test))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc =SVC().fit(X_train, y_train)\n",
    "y_pred_train = pipe_svc.predict(X_train)\n",
    "y_pred_test = pipe_svc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test)\n",
    "print(classification_report(y_train, y_pred_train, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a3090422c93d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mloj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"liblinear\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mloj_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mloj_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "loj = LogisticRegression(solver = \"liblinear\")\n",
    "loj_model = loj.fit(X_train,y_train)\n",
    "loj_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loj_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e7622b950e3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeClassifier()\n",
    "cart_model = cart.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cart_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, cart_model.predict(X_test))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "GradientBoostingClassifier:\n",
      "Accuracy: 99.4259%\n",
      "----------------------------\n",
      "KNeighborsClassifier:\n",
      "Accuracy: 99.3700%\n",
      "----------------------------\n",
      "GaussianNB:\n",
      "Accuracy: 1.8117%\n",
      "----------------------------\n",
      "XGBClassifier:\n",
      "Accuracy: 99.4371%\n"
     ]
    }
   ],
   "source": [
    "modeller = [\n",
    "    gbm_model,\n",
    "    knn_model,\n",
    "    svm_model,\n",
    "    nb_model,\n",
    "    cart_model\n",
    "    xgb_model,\n",
    "    loj_model,\n",
    "    cat_model,\n",
    "    mlpc\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "for model in modeller:\n",
    "    isimler = model.__class__.__name__\n",
    "    y_pred = model.predict(X_test)\n",
    "    dogruluk = accuracy_score(y_test, y_pred)\n",
    "    print(\"-\"*28)\n",
    "    print(isimler + \":\" )\n",
    "    print(\"Accuracy: {:.4%}\".format(dogruluk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sonuc = []\n",
    "\n",
    "sonuclar = pd.DataFrame(columns= [\"Modeller\",\"Accuracy\"])\n",
    "\n",
    "for model in modeller:\n",
    "    isimler = model.__class__.__name__\n",
    "    y_pred = model.predict(X_test)\n",
    "    dogruluk = accuracy_score(y_test, y_pred)    \n",
    "    sonuc = pd.DataFrame([[isimler, dogruluk*100]], columns= [\"Modeller\",\"Accuracy\"])\n",
    "    sonuclar = sonuclar.append(sonuc)\n",
    "    \n",
    "    \n",
    "sns.barplot(x= 'Accuracy', y = 'Modeller', data=sonuclar, color=\"\")\n",
    "plt.xlabel('Accuracy %')\n",
    "plt.title('Modellerin Doruluk Oranlar');    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame({\"Cross Validation Means\":[0.9426983403065574,0.9574115458084643,0.8198176386217473,0.784126066638906], \"ML Models\":[\"DecisionTreeClassifier\",\"RandomForestClassifier\",\n",
    "             \"LogisticRegression\",\n",
    "             \"KNeighborsClassifier\"]})\n",
    "\n",
    "g = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\n",
    "g.set_xlabel(\"Mean Accuracy\")\n",
    "g.set_title(\"Cross Validation Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0     0     0     0     0  1178]\n",
      " [    0     0     0     0     0     0     0    63]\n",
      " [    0     0     0     0     0     0     0   169]\n",
      " [    0     0     0     0     0     0     0   155]\n",
      " [    0     0     0     0     0     0     0   305]\n",
      " [    0     0     0     0     0     0     0   120]\n",
      " [    0     0     0     0     0     0     0    28]\n",
      " [    0     0     0     0     0     0     0 69571]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9718113117937113"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      1178\n",
      "         1.0       0.00      0.00      0.00        63\n",
      "         2.0       0.00      0.00      0.00       169\n",
      "         3.0       0.00      0.00      0.00       155\n",
      "         4.0       0.00      0.00      0.00       305\n",
      "         5.0       0.00      0.00      0.00       120\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "         7.0       0.97      1.00      0.99     69571\n",
      "\n",
      "    accuracy                           0.97     71589\n",
      "   macro avg       0.12      0.12      0.12     71589\n",
      "weighted avg       0.94      0.97      0.96     71589\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\metec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\metec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\metec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Neither the `x` nor `y` variable appears to be numeric.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-3bacd4f3f2e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m    \" xgb_model\"]\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mac\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpalette\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pastel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Plotting the Model Accuracies\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"bold\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36mbarplot\u001b[1;34m(x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge, ax, **kwargs)\u001b[0m\n\u001b[0;32m   3142\u001b[0m             ax=None, **kwargs):\n\u001b[0;32m   3143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3144\u001b[1;33m     plotter = _BarPlotter(x, y, hue, data, order, hue_order,\n\u001b[0m\u001b[0;32m   3145\u001b[0m                           \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3146\u001b[0m                           \u001b[0morient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[0;32m   1600\u001b[0m                  errwidth, capsize, dodge):\n\u001b[0;32m   1601\u001b[0m         \u001b[1;34m\"\"\"Initialize the plotter.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1602\u001b[1;33m         self.establish_variables(x, y, hue, data, orient,\n\u001b[0m\u001b[0;32m   1603\u001b[0m                                  order, hue_order, units)\n\u001b[0;32m   1604\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[1;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[1;31m# Figure out the plotting orientation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[0morient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_orient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;31m# Option 2a:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36minfer_orient\u001b[1;34m(self, x, y, orient)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_not_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_not_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"h\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Neither the `x` nor `y` variable appears to be numeric."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 288x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#comparing accuracies\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(4,4))\n",
    "ac = [gbm_model,\n",
    "    knn_model,\n",
    "    \n",
    "    nb_model,\n",
    "    \n",
    "    xgb_model]\n",
    "name = [\"gbm_model\",\n",
    "   \" knn_model\",\n",
    "    \n",
    "    \"nb_model\",\n",
    "    \n",
    "   \" xgb_model\"]\n",
    "sns.barplot(x = ac,y = name,palette='pastel')\n",
    "plt.title(\"Plotting the Model Accuracies\", fontsize=16, fontweight=\"bold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics Calculations for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tree = pipe_tree.fit(X_train, y_train)\n",
    "y_pred_train = pipe_tree.predict(X_train)\n",
    "y_pred_test = pipe_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred_train, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "for i in cnf_matrix:\n",
    "    for j in i:\n",
    "        print(j, end='&')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics Calculations for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rnd = pipe_rnd.fit(X_train, y_train)\n",
    "y_pred_train = pipe_rnd.predict(X_train)\n",
    "y_pred_test = pipe_rnd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = pipe_rnd.predict(X_train)\n",
    "y_pred_test = pipe_rnd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred_train, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "for i in cnf_matrix:\n",
    "    for j in i:\n",
    "        print(j, end='&')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bu notebooku komple sil zaten ben bu notebookun yerine yaptm benimkini erkan baba sana bii gstercem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
